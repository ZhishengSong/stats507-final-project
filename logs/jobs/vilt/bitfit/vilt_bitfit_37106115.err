2025-12-02 16:15:08 - INFO - bitfit - Using device cuda
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Loading weights:   0%|          | 0/206 [00:00<?, ?it/s]Loading weights:   0%|          | 1/206 [00:00<00:00, 10082.46it/s, Materializing param=embeddings.cls_token]Loading weights:   0%|          | 1/206 [00:00<00:00, 5482.75it/s, Materializing param=embeddings.cls_token] Loading weights:   1%|          | 2/206 [00:00<00:00, 5380.76it/s, Materializing param=embeddings.patch_embeddings.projection.bias]Loading weights:   1%|          | 2/206 [00:00<00:00, 3597.17it/s, Materializing param=embeddings.patch_embeddings.projection.bias]Loading weights:   1%|▏         | 3/206 [00:00<00:04, 48.45it/s, Materializing param=embeddings.patch_embeddings.projection.weight]Loading weights:   1%|▏         | 3/206 [00:00<00:06, 30.92it/s, Materializing param=embeddings.patch_embeddings.projection.weight]Loading weights:   2%|▏         | 4/206 [00:00<00:04, 41.16it/s, Materializing param=embeddings.position_embeddings]               Loading weights:   2%|▏         | 4/206 [00:00<00:04, 41.13it/s, Materializing param=embeddings.position_embeddings]Loading weights:   2%|▏         | 5/206 [00:00<00:05, 35.73it/s, Materializing param=embeddings.position_embeddings]Loading weights:   2%|▏         | 5/206 [00:00<00:05, 35.73it/s, Materializing param=embeddings.text_embeddings.LayerNorm.bias]Loading weights:   2%|▏         | 5/206 [00:00<00:05, 35.73it/s, Materializing param=embeddings.text_embeddings.LayerNorm.bias]Loading weights:   3%|▎         | 6/206 [00:00<00:05, 35.73it/s, Materializing param=embeddings.text_embeddings.LayerNorm.weight]Loading weights:   3%|▎         | 6/206 [00:00<00:05, 35.73it/s, Materializing param=embeddings.text_embeddings.LayerNorm.weight]Loading weights:   3%|▎         | 7/206 [00:00<00:05, 35.73it/s, Materializing param=embeddings.text_embeddings.position_embeddings.weight]Loading weights:   3%|▎         | 7/206 [00:00<00:05, 35.73it/s, Materializing param=embeddings.text_embeddings.position_embeddings.weight]Loading weights:   4%|▍         | 8/206 [00:00<00:05, 35.73it/s, Materializing param=embeddings.text_embeddings.token_type_embeddings.weight]Loading weights:   4%|▍         | 8/206 [00:00<00:05, 35.73it/s, Materializing param=embeddings.text_embeddings.token_type_embeddings.weight]Loading weights:   4%|▍         | 9/206 [00:00<00:06, 28.61it/s, Materializing param=embeddings.text_embeddings.token_type_embeddings.weight]Loading weights:   4%|▍         | 9/206 [00:00<00:06, 28.61it/s, Materializing param=embeddings.text_embeddings.word_embeddings.weight]      Loading weights:   4%|▍         | 9/206 [00:00<00:06, 28.61it/s, Materializing param=embeddings.text_embeddings.word_embeddings.weight]Loading weights:   5%|▍         | 10/206 [00:00<00:06, 28.61it/s, Materializing param=embeddings.token_type_embeddings.weight]         Loading weights:   5%|▍         | 10/206 [00:00<00:06, 28.61it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   5%|▌         | 11/206 [00:00<00:06, 28.61it/s, Materializing param=encoder.layer.0.attention.attention.key.bias]Loading weights:   5%|▌         | 11/206 [00:00<00:06, 28.61it/s, Materializing param=encoder.layer.0.attention.attention.key.bias]Loading weights:   6%|▌         | 12/206 [00:00<00:09, 20.90it/s, Materializing param=encoder.layer.0.attention.attention.key.bias]Loading weights:   6%|▌         | 12/206 [00:00<00:09, 20.90it/s, Materializing param=encoder.layer.0.attention.attention.key.weight]Loading weights:   6%|▌         | 12/206 [00:00<00:09, 20.90it/s, Materializing param=encoder.layer.0.attention.attention.key.weight]Loading weights:   6%|▋         | 13/206 [00:00<00:09, 20.90it/s, Materializing param=encoder.layer.0.attention.attention.query.bias]Loading weights:   6%|▋         | 13/206 [00:00<00:09, 20.90it/s, Materializing param=encoder.layer.0.attention.attention.query.bias]Loading weights:   7%|▋         | 14/206 [00:00<00:09, 20.90it/s, Materializing param=encoder.layer.0.attention.attention.query.weight]Loading weights:   7%|▋         | 14/206 [00:00<00:09, 20.90it/s, Materializing param=encoder.layer.0.attention.attention.query.weight]Loading weights:   7%|▋         | 15/206 [00:00<00:10, 17.93it/s, Materializing param=encoder.layer.0.attention.attention.query.weight]Loading weights:   7%|▋         | 15/206 [00:00<00:10, 17.93it/s, Materializing param=encoder.layer.0.attention.attention.value.bias]  Loading weights:   7%|▋         | 15/206 [00:00<00:10, 17.93it/s, Materializing param=encoder.layer.0.attention.attention.value.bias]Loading weights:   8%|▊         | 16/206 [00:00<00:10, 17.93it/s, Materializing param=encoder.layer.0.attention.attention.value.weight]Loading weights:   8%|▊         | 16/206 [00:00<00:10, 17.93it/s, Materializing param=encoder.layer.0.attention.attention.value.weight]Loading weights:   8%|▊         | 17/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.attention.attention.value.weight]Loading weights:   8%|▊         | 17/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]     Loading weights:   8%|▊         | 17/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]Loading weights:   9%|▊         | 18/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:   9%|▊         | 18/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:   9%|▉         | 19/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]      Loading weights:   9%|▉         | 19/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]Loading weights:  10%|▉         | 20/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  10%|▉         | 20/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  10%|█         | 21/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.layernorm_after.bias]     Loading weights:  10%|█         | 21/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.layernorm_after.bias]Loading weights:  11%|█         | 22/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.layernorm_after.weight]Loading weights:  11%|█         | 22/206 [00:00<00:11, 16.49it/s, Materializing param=encoder.layer.0.layernorm_after.weight]Loading weights:  11%|█         | 23/206 [00:01<00:08, 22.75it/s, Materializing param=encoder.layer.0.layernorm_after.weight]Loading weights:  11%|█         | 23/206 [00:01<00:08, 22.75it/s, Materializing param=encoder.layer.0.layernorm_before.bias] Loading weights:  11%|█         | 23/206 [00:01<00:08, 22.75it/s, Materializing param=encoder.layer.0.layernorm_before.bias]Loading weights:  12%|█▏        | 24/206 [00:01<00:08, 22.75it/s, Materializing param=encoder.layer.0.layernorm_before.weight]Loading weights:  12%|█▏        | 24/206 [00:01<00:08, 22.75it/s, Materializing param=encoder.layer.0.layernorm_before.weight]Loading weights:  12%|█▏        | 25/206 [00:01<00:07, 22.75it/s, Materializing param=encoder.layer.0.output.dense.bias]      Loading weights:  12%|█▏        | 25/206 [00:01<00:07, 22.75it/s, Materializing param=encoder.layer.0.output.dense.bias]Loading weights:  13%|█▎        | 26/206 [00:01<00:09, 19.78it/s, Materializing param=encoder.layer.0.output.dense.bias]Loading weights:  13%|█▎        | 26/206 [00:01<00:09, 19.78it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  13%|█▎        | 26/206 [00:01<00:09, 19.78it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  13%|█▎        | 27/206 [00:01<00:09, 19.78it/s, Materializing param=encoder.layer.1.attention.attention.key.bias]Loading weights:  13%|█▎        | 27/206 [00:01<00:09, 19.78it/s, Materializing param=encoder.layer.1.attention.attention.key.bias]Loading weights:  14%|█▎        | 28/206 [00:01<00:08, 19.78it/s, Materializing param=encoder.layer.1.attention.attention.key.weight]Loading weights:  14%|█▎        | 28/206 [00:01<00:08, 19.78it/s, Materializing param=encoder.layer.1.attention.attention.key.weight]Loading weights:  14%|█▍        | 29/206 [00:01<00:08, 20.10it/s, Materializing param=encoder.layer.1.attention.attention.key.weight]Loading weights:  14%|█▍        | 29/206 [00:01<00:08, 20.10it/s, Materializing param=encoder.layer.1.attention.attention.query.bias]Loading weights:  14%|█▍        | 29/206 [00:01<00:08, 20.10it/s, Materializing param=encoder.layer.1.attention.attention.query.bias]Loading weights:  15%|█▍        | 30/206 [00:01<00:08, 20.10it/s, Materializing param=encoder.layer.1.attention.attention.query.weight]Loading weights:  15%|█▍        | 30/206 [00:01<00:08, 20.10it/s, Materializing param=encoder.layer.1.attention.attention.query.weight]Loading weights:  15%|█▌        | 31/206 [00:01<00:08, 20.10it/s, Materializing param=encoder.layer.1.attention.attention.value.bias]  Loading weights:  15%|█▌        | 31/206 [00:01<00:08, 20.10it/s, Materializing param=encoder.layer.1.attention.attention.value.bias]Loading weights:  16%|█▌        | 32/206 [00:01<00:08, 20.10it/s, Materializing param=encoder.layer.1.attention.attention.value.weight]Loading weights:  16%|█▌        | 32/206 [00:01<00:08, 20.10it/s, Materializing param=encoder.layer.1.attention.attention.value.weight]Loading weights:  16%|█▌        | 33/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.attention.attention.value.weight]Loading weights:  16%|█▌        | 33/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]     Loading weights:  16%|█▌        | 33/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]Loading weights:  17%|█▋        | 34/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  17%|█▋        | 34/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  17%|█▋        | 35/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]      Loading weights:  17%|█▋        | 35/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]Loading weights:  17%|█▋        | 36/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  17%|█▋        | 36/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  18%|█▊        | 37/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.layernorm_after.bias]     Loading weights:  18%|█▊        | 37/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.layernorm_after.bias]Loading weights:  18%|█▊        | 38/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.layernorm_after.weight]Loading weights:  18%|█▊        | 38/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.layernorm_after.weight]Loading weights:  19%|█▉        | 39/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.layernorm_before.bias] Loading weights:  19%|█▉        | 39/206 [00:01<00:07, 23.67it/s, Materializing param=encoder.layer.1.layernorm_before.bias]Loading weights:  19%|█▉        | 40/206 [00:01<00:04, 33.72it/s, Materializing param=encoder.layer.1.layernorm_before.bias]Loading weights:  19%|█▉        | 40/206 [00:01<00:04, 33.72it/s, Materializing param=encoder.layer.1.layernorm_before.weight]Loading weights:  19%|█▉        | 40/206 [00:01<00:04, 33.72it/s, Materializing param=encoder.layer.1.layernorm_before.weight]Loading weights:  20%|█▉        | 41/206 [00:01<00:04, 33.72it/s, Materializing param=encoder.layer.1.output.dense.bias]      Loading weights:  20%|█▉        | 41/206 [00:01<00:04, 33.72it/s, Materializing param=encoder.layer.1.output.dense.bias]Loading weights:  20%|██        | 42/206 [00:01<00:04, 33.72it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  20%|██        | 42/206 [00:01<00:04, 33.72it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  21%|██        | 43/206 [00:01<00:04, 33.72it/s, Materializing param=encoder.layer.2.attention.attention.key.bias]Loading weights:  21%|██        | 43/206 [00:01<00:04, 33.72it/s, Materializing param=encoder.layer.2.attention.attention.key.bias]Loading weights:  21%|██▏       | 44/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.attention.key.bias]Loading weights:  21%|██▏       | 44/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.attention.key.weight]Loading weights:  21%|██▏       | 44/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.attention.key.weight]Loading weights:  22%|██▏       | 45/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.attention.query.bias]Loading weights:  22%|██▏       | 45/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.attention.query.bias]Loading weights:  22%|██▏       | 46/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.attention.query.weight]Loading weights:  22%|██▏       | 46/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.attention.query.weight]Loading weights:  23%|██▎       | 47/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.attention.value.bias]  Loading weights:  23%|██▎       | 47/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.attention.value.bias]Loading weights:  23%|██▎       | 48/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.attention.value.weight]Loading weights:  23%|██▎       | 48/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.attention.value.weight]Loading weights:  24%|██▍       | 49/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]     Loading weights:  24%|██▍       | 49/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]Loading weights:  24%|██▍       | 50/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  24%|██▍       | 50/206 [00:01<00:06, 24.65it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  25%|██▍       | 51/206 [00:02<00:04, 32.59it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  25%|██▍       | 51/206 [00:02<00:04, 32.59it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]      Loading weights:  25%|██▍       | 51/206 [00:02<00:04, 32.59it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]Loading weights:  25%|██▌       | 52/206 [00:02<00:04, 32.59it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  25%|██▌       | 52/206 [00:02<00:04, 32.59it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  26%|██▌       | 53/206 [00:02<00:04, 32.59it/s, Materializing param=encoder.layer.2.layernorm_after.bias]     Loading weights:  26%|██▌       | 53/206 [00:02<00:04, 32.59it/s, Materializing param=encoder.layer.2.layernorm_after.bias]Loading weights:  26%|██▌       | 54/206 [00:02<00:04, 32.59it/s, Materializing param=encoder.layer.2.layernorm_after.weight]Loading weights:  26%|██▌       | 54/206 [00:02<00:04, 32.59it/s, Materializing param=encoder.layer.2.layernorm_after.weight]Loading weights:  27%|██▋       | 55/206 [00:02<00:04, 32.59it/s, Materializing param=encoder.layer.2.layernorm_before.bias] Loading weights:  27%|██▋       | 55/206 [00:02<00:04, 32.59it/s, Materializing param=encoder.layer.2.layernorm_before.bias]Loading weights:  27%|██▋       | 56/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.2.layernorm_before.bias]Loading weights:  27%|██▋       | 56/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.2.layernorm_before.weight]Loading weights:  27%|██▋       | 56/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.2.layernorm_before.weight]Loading weights:  28%|██▊       | 57/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.2.output.dense.bias]      Loading weights:  28%|██▊       | 57/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.2.output.dense.bias]Loading weights:  28%|██▊       | 58/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  28%|██▊       | 58/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  29%|██▊       | 59/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.3.attention.attention.key.bias]Loading weights:  29%|██▊       | 59/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.3.attention.attention.key.bias]Loading weights:  29%|██▉       | 60/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.3.attention.attention.key.weight]Loading weights:  29%|██▉       | 60/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.3.attention.attention.key.weight]Loading weights:  30%|██▉       | 61/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.3.attention.attention.query.bias]Loading weights:  30%|██▉       | 61/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.3.attention.attention.query.bias]Loading weights:  30%|███       | 62/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.3.attention.attention.query.weight]Loading weights:  30%|███       | 62/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.3.attention.attention.query.weight]Loading weights:  31%|███       | 63/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.3.attention.attention.value.bias]  Loading weights:  31%|███       | 63/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.3.attention.attention.value.bias]Loading weights:  31%|███       | 64/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.3.attention.attention.value.weight]Loading weights:  31%|███       | 64/206 [00:02<00:04, 35.49it/s, Materializing param=encoder.layer.3.attention.attention.value.weight]Loading weights:  32%|███▏      | 65/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]     Loading weights:  32%|███▏      | 65/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]Loading weights:  32%|███▏      | 66/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  32%|███▏      | 66/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  33%|███▎      | 67/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]      Loading weights:  33%|███▎      | 67/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]Loading weights:  33%|███▎      | 68/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  33%|███▎      | 68/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  33%|███▎      | 69/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.layernorm_after.bias]     Loading weights:  33%|███▎      | 69/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.layernorm_after.bias]Loading weights:  34%|███▍      | 70/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.layernorm_after.weight]Loading weights:  34%|███▍      | 70/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.layernorm_after.weight]Loading weights:  34%|███▍      | 71/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.layernorm_before.bias] Loading weights:  34%|███▍      | 71/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.layernorm_before.bias]Loading weights:  35%|███▍      | 72/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.layernorm_before.weight]Loading weights:  35%|███▍      | 72/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.layernorm_before.weight]Loading weights:  35%|███▌      | 73/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.output.dense.bias]      Loading weights:  35%|███▌      | 73/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.output.dense.bias]Loading weights:  36%|███▌      | 74/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  36%|███▌      | 74/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  36%|███▋      | 75/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.attention.key.bias]Loading weights:  36%|███▋      | 75/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.attention.key.bias]Loading weights:  37%|███▋      | 76/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.attention.key.weight]Loading weights:  37%|███▋      | 76/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.attention.key.weight]Loading weights:  37%|███▋      | 77/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.attention.query.bias]Loading weights:  37%|███▋      | 77/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.attention.query.bias]Loading weights:  38%|███▊      | 78/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.attention.query.weight]Loading weights:  38%|███▊      | 78/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.attention.query.weight]Loading weights:  38%|███▊      | 79/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.attention.value.bias]  Loading weights:  38%|███▊      | 79/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.attention.value.bias]Loading weights:  39%|███▉      | 80/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.attention.value.weight]Loading weights:  39%|███▉      | 80/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.attention.value.weight]Loading weights:  39%|███▉      | 81/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]     Loading weights:  39%|███▉      | 81/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]Loading weights:  40%|███▉      | 82/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  40%|███▉      | 82/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  40%|████      | 83/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]      Loading weights:  40%|████      | 83/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]Loading weights:  41%|████      | 84/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  41%|████      | 84/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  41%|████▏     | 85/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.layernorm_after.bias]     Loading weights:  41%|████▏     | 85/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.layernorm_after.bias]Loading weights:  42%|████▏     | 86/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.layernorm_after.weight]Loading weights:  42%|████▏     | 86/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.layernorm_after.weight]Loading weights:  42%|████▏     | 87/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.layernorm_before.bias] Loading weights:  42%|████▏     | 87/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.layernorm_before.bias]Loading weights:  43%|████▎     | 88/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.layernorm_before.weight]Loading weights:  43%|████▎     | 88/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.layernorm_before.weight]Loading weights:  43%|████▎     | 89/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.output.dense.bias]      Loading weights:  43%|████▎     | 89/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.output.dense.bias]Loading weights:  44%|████▎     | 90/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  44%|████▎     | 90/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  44%|████▍     | 91/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.attention.key.bias]Loading weights:  44%|████▍     | 91/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.attention.key.bias]Loading weights:  45%|████▍     | 92/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.attention.key.weight]Loading weights:  45%|████▍     | 92/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.attention.key.weight]Loading weights:  45%|████▌     | 93/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.attention.query.bias]Loading weights:  45%|████▌     | 93/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.attention.query.bias]Loading weights:  46%|████▌     | 94/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.attention.query.weight]Loading weights:  46%|████▌     | 94/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.attention.query.weight]Loading weights:  46%|████▌     | 95/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.attention.value.bias]  Loading weights:  46%|████▌     | 95/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.attention.value.bias]Loading weights:  47%|████▋     | 96/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.attention.value.weight]Loading weights:  47%|████▋     | 96/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.attention.value.weight]Loading weights:  47%|████▋     | 97/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]     Loading weights:  47%|████▋     | 97/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]Loading weights:  48%|████▊     | 98/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  48%|████▊     | 98/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  48%|████▊     | 99/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]      Loading weights:  48%|████▊     | 99/206 [00:02<00:03, 35.49it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]Loading weights:  49%|████▊     | 100/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  49%|████▊     | 100/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  49%|████▉     | 101/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.layernorm_after.bias]     Loading weights:  49%|████▉     | 101/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.layernorm_after.bias]Loading weights:  50%|████▉     | 102/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.layernorm_after.weight]Loading weights:  50%|████▉     | 102/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.layernorm_after.weight]Loading weights:  50%|█████     | 103/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.layernorm_before.bias] Loading weights:  50%|█████     | 103/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.layernorm_before.bias]Loading weights:  50%|█████     | 104/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.layernorm_before.weight]Loading weights:  50%|█████     | 104/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.layernorm_before.weight]Loading weights:  51%|█████     | 105/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.output.dense.bias]      Loading weights:  51%|█████     | 105/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.output.dense.bias]Loading weights:  51%|█████▏    | 106/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  51%|█████▏    | 106/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  52%|█████▏    | 107/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.attention.key.bias]Loading weights:  52%|█████▏    | 107/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.attention.key.bias]Loading weights:  52%|█████▏    | 108/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.attention.key.weight]Loading weights:  52%|█████▏    | 108/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.attention.key.weight]Loading weights:  53%|█████▎    | 109/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.attention.query.bias]Loading weights:  53%|█████▎    | 109/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.attention.query.bias]Loading weights:  53%|█████▎    | 110/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.attention.query.weight]Loading weights:  53%|█████▎    | 110/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.attention.query.weight]Loading weights:  54%|█████▍    | 111/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.attention.value.bias]  Loading weights:  54%|█████▍    | 111/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.attention.value.bias]Loading weights:  54%|█████▍    | 112/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.attention.value.weight]Loading weights:  54%|█████▍    | 112/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.attention.value.weight]Loading weights:  55%|█████▍    | 113/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.output.dense.bias]     Loading weights:  55%|█████▍    | 113/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.output.dense.bias]Loading weights:  55%|█████▌    | 114/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.output.dense.weight]Loading weights:  55%|█████▌    | 114/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.attention.output.dense.weight]Loading weights:  56%|█████▌    | 115/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.intermediate.dense.bias]      Loading weights:  56%|█████▌    | 115/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.intermediate.dense.bias]Loading weights:  56%|█████▋    | 116/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.intermediate.dense.weight]Loading weights:  56%|█████▋    | 116/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.intermediate.dense.weight]Loading weights:  57%|█████▋    | 117/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.layernorm_after.bias]     Loading weights:  57%|█████▋    | 117/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.layernorm_after.bias]Loading weights:  57%|█████▋    | 118/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.layernorm_after.weight]Loading weights:  57%|█████▋    | 118/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.layernorm_after.weight]Loading weights:  58%|█████▊    | 119/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.layernorm_before.bias] Loading weights:  58%|█████▊    | 119/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.layernorm_before.bias]Loading weights:  58%|█████▊    | 120/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.layernorm_before.weight]Loading weights:  58%|█████▊    | 120/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.layernorm_before.weight]Loading weights:  59%|█████▊    | 121/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.output.dense.bias]      Loading weights:  59%|█████▊    | 121/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.output.dense.bias]Loading weights:  59%|█████▉    | 122/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.output.dense.weight]Loading weights:  59%|█████▉    | 122/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.6.output.dense.weight]Loading weights:  60%|█████▉    | 123/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.attention.key.bias]Loading weights:  60%|█████▉    | 123/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.attention.key.bias]Loading weights:  60%|██████    | 124/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.attention.key.weight]Loading weights:  60%|██████    | 124/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.attention.key.weight]Loading weights:  61%|██████    | 125/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.attention.query.bias]Loading weights:  61%|██████    | 125/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.attention.query.bias]Loading weights:  61%|██████    | 126/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.attention.query.weight]Loading weights:  61%|██████    | 126/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.attention.query.weight]Loading weights:  62%|██████▏   | 127/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.attention.value.bias]  Loading weights:  62%|██████▏   | 127/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.attention.value.bias]Loading weights:  62%|██████▏   | 128/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.attention.value.weight]Loading weights:  62%|██████▏   | 128/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.attention.value.weight]Loading weights:  63%|██████▎   | 129/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.output.dense.bias]     Loading weights:  63%|██████▎   | 129/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.output.dense.bias]Loading weights:  63%|██████▎   | 130/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.output.dense.weight]Loading weights:  63%|██████▎   | 130/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.attention.output.dense.weight]Loading weights:  64%|██████▎   | 131/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.intermediate.dense.bias]      Loading weights:  64%|██████▎   | 131/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.intermediate.dense.bias]Loading weights:  64%|██████▍   | 132/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.intermediate.dense.weight]Loading weights:  64%|██████▍   | 132/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.intermediate.dense.weight]Loading weights:  65%|██████▍   | 133/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.layernorm_after.bias]     Loading weights:  65%|██████▍   | 133/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.layernorm_after.bias]Loading weights:  65%|██████▌   | 134/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.layernorm_after.weight]Loading weights:  65%|██████▌   | 134/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.layernorm_after.weight]Loading weights:  66%|██████▌   | 135/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.layernorm_before.bias] Loading weights:  66%|██████▌   | 135/206 [00:02<00:02, 35.49it/s, Materializing param=encoder.layer.7.layernorm_before.bias]Loading weights:  66%|██████▌   | 136/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.7.layernorm_before.weight]Loading weights:  66%|██████▌   | 136/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.7.layernorm_before.weight]Loading weights:  67%|██████▋   | 137/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.7.output.dense.bias]      Loading weights:  67%|██████▋   | 137/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.7.output.dense.bias]Loading weights:  67%|██████▋   | 138/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.7.output.dense.weight]Loading weights:  67%|██████▋   | 138/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.7.output.dense.weight]Loading weights:  67%|██████▋   | 139/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.attention.key.bias]Loading weights:  67%|██████▋   | 139/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.attention.key.bias]Loading weights:  68%|██████▊   | 140/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.attention.key.weight]Loading weights:  68%|██████▊   | 140/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.attention.key.weight]Loading weights:  68%|██████▊   | 141/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.attention.query.bias]Loading weights:  68%|██████▊   | 141/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.attention.query.bias]Loading weights:  69%|██████▉   | 142/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.attention.query.weight]Loading weights:  69%|██████▉   | 142/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.attention.query.weight]Loading weights:  69%|██████▉   | 143/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.attention.value.bias]  Loading weights:  69%|██████▉   | 143/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.attention.value.bias]Loading weights:  70%|██████▉   | 144/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.attention.value.weight]Loading weights:  70%|██████▉   | 144/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.attention.value.weight]Loading weights:  70%|███████   | 145/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.output.dense.bias]     Loading weights:  70%|███████   | 145/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.output.dense.bias]Loading weights:  71%|███████   | 146/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.output.dense.weight]Loading weights:  71%|███████   | 146/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.attention.output.dense.weight]Loading weights:  71%|███████▏  | 147/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.intermediate.dense.bias]      Loading weights:  71%|███████▏  | 147/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.intermediate.dense.bias]Loading weights:  72%|███████▏  | 148/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.intermediate.dense.weight]Loading weights:  72%|███████▏  | 148/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.intermediate.dense.weight]Loading weights:  72%|███████▏  | 149/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.layernorm_after.bias]     Loading weights:  72%|███████▏  | 149/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.layernorm_after.bias]Loading weights:  73%|███████▎  | 150/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.layernorm_after.weight]Loading weights:  73%|███████▎  | 150/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.layernorm_after.weight]Loading weights:  73%|███████▎  | 151/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.layernorm_before.bias] Loading weights:  73%|███████▎  | 151/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.layernorm_before.bias]Loading weights:  74%|███████▍  | 152/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.layernorm_before.weight]Loading weights:  74%|███████▍  | 152/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.layernorm_before.weight]Loading weights:  74%|███████▍  | 153/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.output.dense.bias]      Loading weights:  74%|███████▍  | 153/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.output.dense.bias]Loading weights:  75%|███████▍  | 154/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.output.dense.weight]Loading weights:  75%|███████▍  | 154/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.8.output.dense.weight]Loading weights:  75%|███████▌  | 155/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.attention.key.bias]Loading weights:  75%|███████▌  | 155/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.attention.key.bias]Loading weights:  76%|███████▌  | 156/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.attention.key.weight]Loading weights:  76%|███████▌  | 156/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.attention.key.weight]Loading weights:  76%|███████▌  | 157/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.attention.query.bias]Loading weights:  76%|███████▌  | 157/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.attention.query.bias]Loading weights:  77%|███████▋  | 158/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.attention.query.weight]Loading weights:  77%|███████▋  | 158/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.attention.query.weight]Loading weights:  77%|███████▋  | 159/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.attention.value.bias]  Loading weights:  77%|███████▋  | 159/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.attention.value.bias]Loading weights:  78%|███████▊  | 160/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.attention.value.weight]Loading weights:  78%|███████▊  | 160/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.attention.value.weight]Loading weights:  78%|███████▊  | 161/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.output.dense.bias]     Loading weights:  78%|███████▊  | 161/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.output.dense.bias]Loading weights:  79%|███████▊  | 162/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.output.dense.weight]Loading weights:  79%|███████▊  | 162/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.attention.output.dense.weight]Loading weights:  79%|███████▉  | 163/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.intermediate.dense.bias]      Loading weights:  79%|███████▉  | 163/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.intermediate.dense.bias]Loading weights:  80%|███████▉  | 164/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.intermediate.dense.weight]Loading weights:  80%|███████▉  | 164/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.intermediate.dense.weight]Loading weights:  80%|████████  | 165/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.layernorm_after.bias]     Loading weights:  80%|████████  | 165/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.layernorm_after.bias]Loading weights:  81%|████████  | 166/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.layernorm_after.weight]Loading weights:  81%|████████  | 166/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.layernorm_after.weight]Loading weights:  81%|████████  | 167/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.layernorm_before.bias] Loading weights:  81%|████████  | 167/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.layernorm_before.bias]Loading weights:  82%|████████▏ | 168/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.layernorm_before.weight]Loading weights:  82%|████████▏ | 168/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.layernorm_before.weight]Loading weights:  82%|████████▏ | 169/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.output.dense.bias]      Loading weights:  82%|████████▏ | 169/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.output.dense.bias]Loading weights:  83%|████████▎ | 170/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.output.dense.weight]Loading weights:  83%|████████▎ | 170/206 [00:02<00:01, 35.49it/s, Materializing param=encoder.layer.9.output.dense.weight]Loading weights:  83%|████████▎ | 171/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.attention.key.bias]Loading weights:  83%|████████▎ | 171/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.attention.key.bias]Loading weights:  83%|████████▎ | 172/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.attention.key.weight]Loading weights:  83%|████████▎ | 172/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.attention.key.weight]Loading weights:  84%|████████▍ | 173/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.attention.query.bias]Loading weights:  84%|████████▍ | 173/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.attention.query.bias]Loading weights:  84%|████████▍ | 174/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.attention.query.weight]Loading weights:  84%|████████▍ | 174/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.attention.query.weight]Loading weights:  85%|████████▍ | 175/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.attention.value.bias]  Loading weights:  85%|████████▍ | 175/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.attention.value.bias]Loading weights:  85%|████████▌ | 176/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.attention.value.weight]Loading weights:  85%|████████▌ | 176/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.attention.value.weight]Loading weights:  86%|████████▌ | 177/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.output.dense.bias]     Loading weights:  86%|████████▌ | 177/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.output.dense.bias]Loading weights:  86%|████████▋ | 178/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.output.dense.weight]Loading weights:  86%|████████▋ | 178/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.attention.output.dense.weight]Loading weights:  87%|████████▋ | 179/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.intermediate.dense.bias]      Loading weights:  87%|████████▋ | 179/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.intermediate.dense.bias]Loading weights:  87%|████████▋ | 180/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.intermediate.dense.weight]Loading weights:  87%|████████▋ | 180/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.intermediate.dense.weight]Loading weights:  88%|████████▊ | 181/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.layernorm_after.bias]     Loading weights:  88%|████████▊ | 181/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.layernorm_after.bias]Loading weights:  88%|████████▊ | 182/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.layernorm_after.weight]Loading weights:  88%|████████▊ | 182/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.layernorm_after.weight]Loading weights:  89%|████████▉ | 183/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.layernorm_before.bias] Loading weights:  89%|████████▉ | 183/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.layernorm_before.bias]Loading weights:  89%|████████▉ | 184/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.layernorm_before.weight]Loading weights:  89%|████████▉ | 184/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.layernorm_before.weight]Loading weights:  90%|████████▉ | 185/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.output.dense.bias]      Loading weights:  90%|████████▉ | 185/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.output.dense.bias]Loading weights:  90%|█████████ | 186/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.output.dense.weight]Loading weights:  90%|█████████ | 186/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.10.output.dense.weight]Loading weights:  91%|█████████ | 187/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.attention.key.bias]Loading weights:  91%|█████████ | 187/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.attention.key.bias]Loading weights:  91%|█████████▏| 188/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.attention.key.weight]Loading weights:  91%|█████████▏| 188/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.attention.key.weight]Loading weights:  92%|█████████▏| 189/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.attention.query.bias]Loading weights:  92%|█████████▏| 189/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.attention.query.bias]Loading weights:  92%|█████████▏| 190/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.attention.query.weight]Loading weights:  92%|█████████▏| 190/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.attention.query.weight]Loading weights:  93%|█████████▎| 191/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.attention.value.bias]  Loading weights:  93%|█████████▎| 191/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.attention.value.bias]Loading weights:  93%|█████████▎| 192/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.attention.value.weight]Loading weights:  93%|█████████▎| 192/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.attention.value.weight]Loading weights:  94%|█████████▎| 193/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.output.dense.bias]     Loading weights:  94%|█████████▎| 193/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.output.dense.bias]Loading weights:  94%|█████████▍| 194/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.output.dense.weight]Loading weights:  94%|█████████▍| 194/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.attention.output.dense.weight]Loading weights:  95%|█████████▍| 195/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.intermediate.dense.bias]      Loading weights:  95%|█████████▍| 195/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.intermediate.dense.bias]Loading weights:  95%|█████████▌| 196/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.intermediate.dense.weight]Loading weights:  95%|█████████▌| 196/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.intermediate.dense.weight]Loading weights:  96%|█████████▌| 197/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.layernorm_after.bias]     Loading weights:  96%|█████████▌| 197/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.layernorm_after.bias]Loading weights:  96%|█████████▌| 198/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.layernorm_after.weight]Loading weights:  96%|█████████▌| 198/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.layernorm_after.weight]Loading weights:  97%|█████████▋| 199/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.layernorm_before.bias] Loading weights:  97%|█████████▋| 199/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.layernorm_before.bias]Loading weights:  97%|█████████▋| 200/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.layernorm_before.weight]Loading weights:  97%|█████████▋| 200/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.layernorm_before.weight]Loading weights:  98%|█████████▊| 201/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.output.dense.bias]      Loading weights:  98%|█████████▊| 201/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.output.dense.bias]Loading weights:  98%|█████████▊| 202/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.output.dense.weight]Loading weights:  98%|█████████▊| 202/206 [00:02<00:00, 35.49it/s, Materializing param=encoder.layer.11.output.dense.weight]Loading weights:  99%|█████████▊| 203/206 [00:02<00:00, 35.49it/s, Materializing param=layernorm.bias]                      Loading weights:  99%|█████████▊| 203/206 [00:02<00:00, 35.49it/s, Materializing param=layernorm.bias]Loading weights:  99%|█████████▉| 204/206 [00:02<00:00, 35.49it/s, Materializing param=layernorm.weight]Loading weights:  99%|█████████▉| 204/206 [00:02<00:00, 35.49it/s, Materializing param=layernorm.weight]Loading weights: 100%|█████████▉| 205/206 [00:02<00:00, 35.49it/s, Materializing param=pooler.dense.bias]Loading weights: 100%|█████████▉| 205/206 [00:02<00:00, 35.49it/s, Materializing param=pooler.dense.bias]Loading weights: 100%|██████████| 206/206 [00:02<00:00, 35.49it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|██████████| 206/206 [00:02<00:00, 35.49it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|██████████| 206/206 [00:02<00:00, 96.03it/s, Materializing param=pooler.dense.weight]
ViltModel LOAD REPORT from: dandelin/vilt-b32-mlm
Key                                          | Status     |  | 
---------------------------------------------+------------+--+-
mlm_score.decoder.weight                     | UNEXPECTED |  | 
mlm_score.transform.dense.weight             | UNEXPECTED |  | 
mlm_score.transform.LayerNorm.bias           | UNEXPECTED |  | 
vilt.embeddings.text_embeddings.position_ids | UNEXPECTED |  | 
mlm_score.transform.dense.bias               | UNEXPECTED |  | 
mlm_score.transform.LayerNorm.weight         | UNEXPECTED |  | 
mlm_score.bias                               | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
/home/zhisheng/stats507/train/run_vilt_bitfit.py:134: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=args.use_amp)
2025-12-02 16:15:21 - INFO - bitfit - Epoch 1/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 16:31:08 - INFO - bitfit - Train metrics: {
  "accuracy": 0.5909411764705882,
  "auroc": 0.4584352618298547,
  "macro_f1": 0.4333084621430322,
  "loss": 0.6777351505055147
}
2025-12-02 16:32:54 - INFO - bitfit - Val metrics: {
  "accuracy": 0.5711538461538461,
  "auroc": 0.48036186531155806,
  "macro_f1": 0.38329318037983096,
  "loss": 0.7000705764843868
}
2025-12-02 16:32:57 - INFO - bitfit - Saved new best checkpoint with AUROC=0.4804
2025-12-02 16:32:57 - INFO - bitfit - Epoch 2/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 16:48:36 - INFO - bitfit - Train metrics: {
  "accuracy": 0.6436470588235295,
  "auroc": 0.5079679635252958,
  "macro_f1": 0.39688253874865415,
  "loss": 0.6545539407169118
}
2025-12-02 16:50:26 - INFO - bitfit - Val metrics: {
  "accuracy": 0.5721153846153846,
  "auroc": 0.5224619064326161,
  "macro_f1": 0.36803496836761024,
  "loss": 0.6970952446644123
}
2025-12-02 16:50:28 - INFO - bitfit - Saved new best checkpoint with AUROC=0.5225
2025-12-02 16:50:28 - INFO - bitfit - Epoch 3/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 17:06:17 - INFO - bitfit - Train metrics: {
  "accuracy": 0.6452941176470588,
  "auroc": 0.580454603058571,
  "macro_f1": 0.39628006753182543,
  "loss": 0.6420822035845588
}
2025-12-02 17:08:07 - INFO - bitfit - Val metrics: {
  "accuracy": 0.5721153846153846,
  "auroc": 0.5384406442047602,
  "macro_f1": 0.36803496836761024,
  "loss": 0.6940301198225755
}
2025-12-02 17:08:09 - INFO - bitfit - Saved new best checkpoint with AUROC=0.5384
2025-12-02 17:08:09 - INFO - bitfit - Epoch 4/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 17:23:25 - INFO - bitfit - Train metrics: {
  "accuracy": 0.6475294117647059,
  "auroc": 0.6205713567765401,
  "macro_f1": 0.4157121799942383,
  "loss": 0.6320902458639706
}
2025-12-02 17:25:08 - INFO - bitfit - Val metrics: {
  "accuracy": 0.5778846153846153,
  "auroc": 0.5416171516310724,
  "macro_f1": 0.38828365438080065,
  "loss": 0.6984220018753639
}
2025-12-02 17:25:10 - INFO - bitfit - Saved new best checkpoint with AUROC=0.5416
2025-12-02 17:25:10 - INFO - bitfit - Epoch 5/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 17:40:20 - INFO - bitfit - Train metrics: {
  "accuracy": 0.6545882352941177,
  "auroc": 0.6477156262481387,
  "macro_f1": 0.4600558602892158,
  "loss": 0.6221488396139706
}
2025-12-02 17:42:06 - INFO - bitfit - Val metrics: {
  "accuracy": 0.5778846153846153,
  "auroc": 0.5480135510863127,
  "macro_f1": 0.413161199435989,
  "loss": 0.7013619973109319
}
2025-12-02 17:42:08 - INFO - bitfit - Saved new best checkpoint with AUROC=0.5480
2025-12-02 17:42:08 - INFO - bitfit - Epoch 6/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 17:57:25 - INFO - bitfit - Train metrics: {
  "accuracy": 0.6661176470588235,
  "auroc": 0.6648669597807814,
  "macro_f1": 0.5130134011250657,
  "loss": 0.6141308880974264
}
2025-12-02 17:59:10 - INFO - bitfit - Val metrics: {
  "accuracy": 0.573076923076923,
  "auroc": 0.553968559367113,
  "macro_f1": 0.4307692307692307,
  "loss": 0.6995024791130653
}
2025-12-02 17:59:12 - INFO - bitfit - Saved new best checkpoint with AUROC=0.5540
2025-12-02 17:59:12 - INFO - bitfit - Epoch 7/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 18:14:43 - INFO - bitfit - Train metrics: {
  "accuracy": 0.6738823529411765,
  "auroc": 0.677214048905977,
  "macro_f1": 0.5490631261098307,
  "loss": 0.6080937930836398
}
2025-12-02 18:16:25 - INFO - bitfit - Val metrics: {
  "accuracy": 0.5798076923076924,
  "auroc": 0.5550437429971593,
  "macro_f1": 0.44745349347553065,
  "loss": 0.7025522782252385
}
2025-12-02 18:16:27 - INFO - bitfit - Saved new best checkpoint with AUROC=0.5550
2025-12-02 18:16:27 - INFO - bitfit - Epoch 8/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 18:33:07 - INFO - bitfit - Train metrics: {
  "accuracy": 0.6789411764705883,
  "auroc": 0.6873168225637072,
  "macro_f1": 0.5626545752074343,
  "loss": 0.6027998334099265
}
2025-12-02 18:34:56 - INFO - bitfit - Val metrics: {
  "accuracy": 0.5836538461538462,
  "auroc": 0.5593520226656254,
  "macro_f1": 0.466717825375904,
  "loss": 0.6999108736331646
}
2025-12-02 18:34:59 - INFO - bitfit - Saved new best checkpoint with AUROC=0.5594
2025-12-02 18:34:59 - INFO - bitfit - Epoch 9/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 18:51:20 - INFO - bitfit - Train metrics: {
  "accuracy": 0.6812941176470588,
  "auroc": 0.694663621306378,
  "macro_f1": 0.5764505980707381,
  "loss": 0.5989571748621324
}
2025-12-02 18:53:05 - INFO - bitfit - Val metrics: {
  "accuracy": 0.5807692307692308,
  "auroc": 0.558401333982216,
  "macro_f1": 0.4547378547378548,
  "loss": 0.7067074014590337
}
2025-12-02 18:53:05 - INFO - bitfit - Epoch 10/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 19:09:39 - INFO - bitfit - Train metrics: {
  "accuracy": 0.6864705882352942,
  "auroc": 0.6942184990408311,
  "macro_f1": 0.5857678519975279,
  "loss": 0.5989924460018382
}
2025-12-02 19:11:29 - INFO - bitfit - Val metrics: {
  "accuracy": 0.5826923076923077,
  "auroc": 0.5592727986086746,
  "macro_f1": 0.4585386686116536,
  "loss": 0.7054971190599295
}
2025-12-02 19:11:29 - INFO - bitfit - Evaluating best checkpoint on test split.
2025-12-02 19:17:15 - INFO - bitfit - Test metrics: {
  "accuracy": 0.5953333333333334,
  "auroc": 0.581664681085044,
  "macro_f1": 0.46140067767093207,
  "loss": 0.6822674278418223
}
2025-12-02 19:17:15 - INFO - bitfit - Saved test predictions to logs/predictions/vilt_bitfit/test_predictions.csv
