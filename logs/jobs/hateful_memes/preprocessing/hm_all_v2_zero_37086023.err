2025-12-02 10:40:37 - INFO - train - Using device cuda
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Loading weights:   0%|          | 0/206 [00:00<?, ?it/s]Loading weights:   0%|          | 1/206 [00:00<00:00, 20164.92it/s, Materializing param=embeddings.cls_token]Loading weights:   0%|          | 1/206 [00:00<00:00, 4911.36it/s, Materializing param=embeddings.cls_token] Loading weights:   1%|          | 2/206 [00:00<00:00, 5475.59it/s, Materializing param=embeddings.patch_embeddings.projection.bias]Loading weights:   1%|          | 2/206 [00:00<00:00, 2747.66it/s, Materializing param=embeddings.patch_embeddings.projection.bias]Loading weights:   1%|▏         | 3/206 [00:00<00:00, 3340.30it/s, Materializing param=embeddings.patch_embeddings.projection.weight]Loading weights:   1%|▏         | 3/206 [00:00<00:00, 2657.43it/s, Materializing param=embeddings.patch_embeddings.projection.weight]Loading weights:   2%|▏         | 4/206 [00:00<00:00, 3124.83it/s, Materializing param=embeddings.position_embeddings]               Loading weights:   2%|▏         | 4/206 [00:00<00:00, 2823.50it/s, Materializing param=embeddings.position_embeddings]Loading weights:   2%|▏         | 5/206 [00:00<00:00, 2516.99it/s, Materializing param=embeddings.text_embeddings.LayerNorm.bias]Loading weights:   2%|▏         | 5/206 [00:00<00:00, 2411.35it/s, Materializing param=embeddings.text_embeddings.LayerNorm.bias]Loading weights:   3%|▎         | 6/206 [00:00<00:00, 2547.15it/s, Materializing param=embeddings.text_embeddings.LayerNorm.weight]Loading weights:   3%|▎         | 6/206 [00:00<00:00, 2274.57it/s, Materializing param=embeddings.text_embeddings.LayerNorm.weight]Loading weights:   3%|▎         | 7/206 [00:00<00:00, 2341.69it/s, Materializing param=embeddings.text_embeddings.position_embeddings.weight]Loading weights:   3%|▎         | 7/206 [00:00<00:00, 2182.58it/s, Materializing param=embeddings.text_embeddings.position_embeddings.weight]Loading weights:   4%|▍         | 8/206 [00:00<00:00, 2383.80it/s, Materializing param=embeddings.text_embeddings.token_type_embeddings.weight]Loading weights:   4%|▍         | 8/206 [00:00<00:00, 2097.28it/s, Materializing param=embeddings.text_embeddings.token_type_embeddings.weight]Loading weights:   4%|▍         | 9/206 [00:00<00:00, 1953.16it/s, Materializing param=embeddings.text_embeddings.word_embeddings.weight]      Loading weights:   4%|▍         | 9/206 [00:00<00:00, 1883.95it/s, Materializing param=embeddings.text_embeddings.word_embeddings.weight]Loading weights:   5%|▍         | 10/206 [00:00<00:00, 1908.15it/s, Materializing param=embeddings.token_type_embeddings.weight]         Loading weights:   5%|▍         | 10/206 [00:00<00:00, 1796.74it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   5%|▌         | 11/206 [00:00<00:00, 1920.55it/s, Materializing param=encoder.layer.0.attention.attention.key.bias]Loading weights:   5%|▌         | 11/206 [00:00<00:00, 1801.47it/s, Materializing param=encoder.layer.0.attention.attention.key.bias]Loading weights:   6%|▌         | 12/206 [00:00<00:00, 1851.93it/s, Materializing param=encoder.layer.0.attention.attention.key.weight]Loading weights:   6%|▌         | 12/206 [00:00<00:00, 1750.91it/s, Materializing param=encoder.layer.0.attention.attention.key.weight]Loading weights:   6%|▋         | 13/206 [00:00<00:00, 1856.01it/s, Materializing param=encoder.layer.0.attention.attention.query.bias]Loading weights:   6%|▋         | 13/206 [00:00<00:00, 1820.44it/s, Materializing param=encoder.layer.0.attention.attention.query.bias]Loading weights:   7%|▋         | 14/206 [00:00<00:00, 1819.20it/s, Materializing param=encoder.layer.0.attention.attention.query.weight]Loading weights:   7%|▋         | 14/206 [00:00<00:00, 1784.97it/s, Materializing param=encoder.layer.0.attention.attention.query.weight]Loading weights:   7%|▋         | 15/206 [00:00<00:00, 1827.85it/s, Materializing param=encoder.layer.0.attention.attention.value.bias]  Loading weights:   7%|▋         | 15/206 [00:00<00:00, 1812.73it/s, Materializing param=encoder.layer.0.attention.attention.value.bias]Loading weights:   8%|▊         | 16/206 [00:00<00:00, 1886.30it/s, Materializing param=encoder.layer.0.attention.attention.value.weight]Loading weights:   8%|▊         | 16/206 [00:00<00:00, 1871.47it/s, Materializing param=encoder.layer.0.attention.attention.value.weight]Loading weights:   8%|▊         | 17/206 [00:00<00:00, 1953.14it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]     Loading weights:   8%|▊         | 17/206 [00:00<00:00, 1891.23it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]Loading weights:   9%|▊         | 18/206 [00:00<00:00, 1953.16it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:   9%|▊         | 18/206 [00:00<00:00, 1910.60it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:   9%|▉         | 19/206 [00:00<00:00, 1955.91it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]      Loading weights:   9%|▉         | 19/206 [00:00<00:00, 1913.05it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]Loading weights:  10%|▉         | 20/206 [00:00<00:00, 1942.57it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  10%|▉         | 20/206 [00:00<00:00, 1929.97it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  10%|█         | 21/206 [00:00<00:00, 1984.69it/s, Materializing param=encoder.layer.0.layernorm_after.bias]     Loading weights:  10%|█         | 21/206 [00:00<00:00, 1961.57it/s, Materializing param=encoder.layer.0.layernorm_after.bias]Loading weights:  11%|█         | 22/206 [00:00<00:00, 2026.77it/s, Materializing param=encoder.layer.0.layernorm_after.weight]Loading weights:  11%|█         | 22/206 [00:00<00:00, 1950.47it/s, Materializing param=encoder.layer.0.layernorm_after.weight]Loading weights:  11%|█         | 23/206 [00:00<00:00, 2013.59it/s, Materializing param=encoder.layer.0.layernorm_before.bias] Loading weights:  11%|█         | 23/206 [00:00<00:00, 2001.18it/s, Materializing param=encoder.layer.0.layernorm_before.bias]Loading weights:  12%|█▏        | 24/206 [00:00<00:00, 2065.74it/s, Materializing param=encoder.layer.0.layernorm_before.weight]Loading weights:  12%|█▏        | 24/206 [00:00<00:00, 2054.56it/s, Materializing param=encoder.layer.0.layernorm_before.weight]Loading weights:  12%|█▏        | 25/206 [00:00<00:00, 2105.36it/s, Materializing param=encoder.layer.0.output.dense.bias]      Loading weights:  12%|█▏        | 25/206 [00:00<00:00, 2094.01it/s, Materializing param=encoder.layer.0.output.dense.bias]Loading weights:  13%|█▎        | 26/206 [00:00<00:00, 2138.61it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  13%|█▎        | 26/206 [00:00<00:00, 2127.09it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  13%|█▎        | 27/206 [00:00<00:00, 2118.73it/s, Materializing param=encoder.layer.1.attention.attention.key.bias]Loading weights:  13%|█▎        | 27/206 [00:00<00:00, 2000.29it/s, Materializing param=encoder.layer.1.attention.attention.key.bias]Loading weights:  14%|█▎        | 28/206 [00:00<00:00, 2017.91it/s, Materializing param=encoder.layer.1.attention.attention.key.weight]Loading weights:  14%|█▎        | 28/206 [00:00<00:00, 1993.36it/s, Materializing param=encoder.layer.1.attention.attention.key.weight]Loading weights:  14%|█▍        | 29/206 [00:00<00:00, 2035.63it/s, Materializing param=encoder.layer.1.attention.attention.query.bias]Loading weights:  14%|█▍        | 29/206 [00:00<00:00, 2004.66it/s, Materializing param=encoder.layer.1.attention.attention.query.bias]Loading weights:  15%|█▍        | 30/206 [00:00<00:00, 2053.68it/s, Materializing param=encoder.layer.1.attention.attention.query.weight]Loading weights:  15%|█▍        | 30/206 [00:00<00:00, 2022.85it/s, Materializing param=encoder.layer.1.attention.attention.query.weight]Loading weights:  15%|█▌        | 31/206 [00:00<00:00, 2036.10it/s, Materializing param=encoder.layer.1.attention.attention.value.bias]  Loading weights:  15%|█▌        | 31/206 [00:00<00:00, 2010.35it/s, Materializing param=encoder.layer.1.attention.attention.value.bias]Loading weights:  16%|█▌        | 32/206 [00:00<00:00, 2036.35it/s, Materializing param=encoder.layer.1.attention.attention.value.weight]Loading weights:  16%|█▌        | 32/206 [00:00<00:00, 2027.55it/s, Materializing param=encoder.layer.1.attention.attention.value.weight]Loading weights:  16%|█▌        | 33/206 [00:00<00:00, 2052.80it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]     Loading weights:  16%|█▌        | 33/206 [00:00<00:00, 2044.31it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]Loading weights:  17%|█▋        | 34/206 [00:00<00:00, 2069.43it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  17%|█▋        | 34/206 [00:00<00:00, 2059.65it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  17%|█▋        | 35/206 [00:00<00:00, 2063.86it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]      Loading weights:  17%|█▋        | 35/206 [00:00<00:00, 2055.74it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]Loading weights:  17%|█▋        | 36/206 [00:00<00:00, 2089.03it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  17%|█▋        | 36/206 [00:00<00:00, 2081.05it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  18%|█▊        | 37/206 [00:00<00:00, 2041.67it/s, Materializing param=encoder.layer.1.layernorm_after.bias]     Loading weights:  18%|█▊        | 37/206 [00:00<00:00, 2026.00it/s, Materializing param=encoder.layer.1.layernorm_after.bias]Loading weights:  18%|█▊        | 38/206 [00:00<00:00, 2055.63it/s, Materializing param=encoder.layer.1.layernorm_after.weight]Loading weights:  18%|█▊        | 38/206 [00:00<00:00, 2048.18it/s, Materializing param=encoder.layer.1.layernorm_after.weight]Loading weights:  19%|█▉        | 39/206 [00:00<00:00, 2071.26it/s, Materializing param=encoder.layer.1.layernorm_before.bias] Loading weights:  19%|█▉        | 39/206 [00:00<00:00, 2064.05it/s, Materializing param=encoder.layer.1.layernorm_before.bias]Loading weights:  19%|█▉        | 40/206 [00:00<00:00, 2084.80it/s, Materializing param=encoder.layer.1.layernorm_before.weight]Loading weights:  19%|█▉        | 40/206 [00:00<00:00, 2077.73it/s, Materializing param=encoder.layer.1.layernorm_before.weight]Loading weights:  20%|█▉        | 41/206 [00:00<00:00, 2106.81it/s, Materializing param=encoder.layer.1.output.dense.bias]      Loading weights:  20%|█▉        | 41/206 [00:00<00:00, 2099.71it/s, Materializing param=encoder.layer.1.output.dense.bias]Loading weights:  20%|██        | 42/206 [00:00<00:00, 2135.80it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  20%|██        | 42/206 [00:00<00:00, 2106.08it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  21%|██        | 43/206 [00:00<00:00, 2134.46it/s, Materializing param=encoder.layer.2.attention.attention.key.bias]Loading weights:  21%|██        | 43/206 [00:00<00:00, 2127.41it/s, Materializing param=encoder.layer.2.attention.attention.key.bias]Loading weights:  21%|██▏       | 44/206 [00:00<00:00, 2151.80it/s, Materializing param=encoder.layer.2.attention.attention.key.weight]Loading weights:  21%|██▏       | 44/206 [00:00<00:00, 2138.24it/s, Materializing param=encoder.layer.2.attention.attention.key.weight]Loading weights:  22%|██▏       | 45/206 [00:00<00:00, 2169.79it/s, Materializing param=encoder.layer.2.attention.attention.query.bias]Loading weights:  22%|██▏       | 45/206 [00:00<00:00, 2155.30it/s, Materializing param=encoder.layer.2.attention.attention.query.bias]Loading weights:  22%|██▏       | 46/206 [00:00<00:00, 2174.41it/s, Materializing param=encoder.layer.2.attention.attention.query.weight]Loading weights:  22%|██▏       | 46/206 [00:00<00:00, 2165.77it/s, Materializing param=encoder.layer.2.attention.attention.query.weight]Loading weights:  23%|██▎       | 47/206 [00:00<00:00, 2184.00it/s, Materializing param=encoder.layer.2.attention.attention.value.bias]  Loading weights:  23%|██▎       | 47/206 [00:00<00:00, 2177.32it/s, Materializing param=encoder.layer.2.attention.attention.value.bias]Loading weights:  23%|██▎       | 48/206 [00:00<00:00, 2207.58it/s, Materializing param=encoder.layer.2.attention.attention.value.weight]Loading weights:  23%|██▎       | 48/206 [00:00<00:00, 2200.80it/s, Materializing param=encoder.layer.2.attention.attention.value.weight]Loading weights:  24%|██▍       | 49/206 [00:00<00:00, 2180.15it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]     Loading weights:  24%|██▍       | 49/206 [00:00<00:00, 2173.42it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]Loading weights:  24%|██▍       | 50/206 [00:00<00:00, 2199.56it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  24%|██▍       | 50/206 [00:00<00:00, 2193.10it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  25%|██▍       | 51/206 [00:00<00:00, 2216.45it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]      Loading weights:  25%|██▍       | 51/206 [00:00<00:00, 2210.11it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]Loading weights:  25%|██▌       | 52/206 [00:00<00:00, 2225.30it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  25%|██▌       | 52/206 [00:00<00:00, 2208.51it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  26%|██▌       | 53/206 [00:00<00:00, 2188.86it/s, Materializing param=encoder.layer.2.layernorm_after.bias]     Loading weights:  26%|██▌       | 53/206 [00:00<00:00, 2182.77it/s, Materializing param=encoder.layer.2.layernorm_after.bias]Loading weights:  26%|██▌       | 54/206 [00:00<00:00, 2204.16it/s, Materializing param=encoder.layer.2.layernorm_after.weight]Loading weights:  26%|██▌       | 54/206 [00:00<00:00, 2128.01it/s, Materializing param=encoder.layer.2.layernorm_after.weight]Loading weights:  27%|██▋       | 55/206 [00:00<00:00, 2155.61it/s, Materializing param=encoder.layer.2.layernorm_before.bias] Loading weights:  27%|██▋       | 55/206 [00:00<00:00, 2147.04it/s, Materializing param=encoder.layer.2.layernorm_before.bias]Loading weights:  27%|██▋       | 56/206 [00:00<00:00, 2168.92it/s, Materializing param=encoder.layer.2.layernorm_before.weight]Loading weights:  27%|██▋       | 56/206 [00:00<00:00, 2162.45it/s, Materializing param=encoder.layer.2.layernorm_before.weight]Loading weights:  28%|██▊       | 57/206 [00:00<00:00, 2190.66it/s, Materializing param=encoder.layer.2.output.dense.bias]      Loading weights:  28%|██▊       | 57/206 [00:00<00:00, 2183.48it/s, Materializing param=encoder.layer.2.output.dense.bias]Loading weights:  28%|██▊       | 58/206 [00:00<00:00, 2211.70it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  28%|██▊       | 58/206 [00:00<00:00, 2206.67it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  29%|██▊       | 59/206 [00:00<00:00, 2234.66it/s, Materializing param=encoder.layer.3.attention.attention.key.bias]Loading weights:  29%|██▊       | 59/206 [00:00<00:00, 2228.88it/s, Materializing param=encoder.layer.3.attention.attention.key.bias]Loading weights:  29%|██▉       | 60/206 [00:00<00:00, 2256.44it/s, Materializing param=encoder.layer.3.attention.attention.key.weight]Loading weights:  29%|██▉       | 60/206 [00:00<00:00, 2251.23it/s, Materializing param=encoder.layer.3.attention.attention.key.weight]Loading weights:  30%|██▉       | 61/206 [00:00<00:00, 2278.82it/s, Materializing param=encoder.layer.3.attention.attention.query.bias]Loading weights:  30%|██▉       | 61/206 [00:00<00:00, 2273.66it/s, Materializing param=encoder.layer.3.attention.attention.query.bias]Loading weights:  30%|███       | 62/206 [00:00<00:00, 2300.93it/s, Materializing param=encoder.layer.3.attention.attention.query.weight]Loading weights:  30%|███       | 62/206 [00:00<00:00, 2295.73it/s, Materializing param=encoder.layer.3.attention.attention.query.weight]Loading weights:  31%|███       | 63/206 [00:00<00:00, 2322.71it/s, Materializing param=encoder.layer.3.attention.attention.value.bias]  Loading weights:  31%|███       | 63/206 [00:00<00:00, 2317.46it/s, Materializing param=encoder.layer.3.attention.attention.value.bias]Loading weights:  31%|███       | 64/206 [00:00<00:00, 2344.19it/s, Materializing param=encoder.layer.3.attention.attention.value.weight]Loading weights:  31%|███       | 64/206 [00:00<00:00, 2338.92it/s, Materializing param=encoder.layer.3.attention.attention.value.weight]Loading weights:  32%|███▏      | 65/206 [00:00<00:00, 2364.69it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]     Loading weights:  32%|███▏      | 65/206 [00:00<00:00, 2359.29it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]Loading weights:  32%|███▏      | 66/206 [00:00<00:00, 2385.51it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  32%|███▏      | 66/206 [00:00<00:00, 2380.24it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  33%|███▎      | 67/206 [00:00<00:00, 2406.21it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]      Loading weights:  33%|███▎      | 67/206 [00:00<00:00, 2400.94it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]Loading weights:  33%|███▎      | 68/206 [00:00<00:00, 2426.87it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  33%|███▎      | 68/206 [00:00<00:00, 2421.59it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  33%|███▎      | 69/206 [00:00<00:00, 2447.31it/s, Materializing param=encoder.layer.3.layernorm_after.bias]     Loading weights:  33%|███▎      | 69/206 [00:00<00:00, 2442.11it/s, Materializing param=encoder.layer.3.layernorm_after.bias]Loading weights:  34%|███▍      | 70/206 [00:00<00:00, 2467.88it/s, Materializing param=encoder.layer.3.layernorm_after.weight]Loading weights:  34%|███▍      | 70/206 [00:00<00:00, 2462.68it/s, Materializing param=encoder.layer.3.layernorm_after.weight]Loading weights:  34%|███▍      | 71/206 [00:00<00:00, 2487.45it/s, Materializing param=encoder.layer.3.layernorm_before.bias] Loading weights:  34%|███▍      | 71/206 [00:00<00:00, 2482.19it/s, Materializing param=encoder.layer.3.layernorm_before.bias]Loading weights:  35%|███▍      | 72/206 [00:00<00:00, 2507.60it/s, Materializing param=encoder.layer.3.layernorm_before.weight]Loading weights:  35%|███▍      | 72/206 [00:00<00:00, 2502.40it/s, Materializing param=encoder.layer.3.layernorm_before.weight]Loading weights:  35%|███▌      | 73/206 [00:00<00:00, 2527.57it/s, Materializing param=encoder.layer.3.output.dense.bias]      Loading weights:  35%|███▌      | 73/206 [00:00<00:00, 2522.48it/s, Materializing param=encoder.layer.3.output.dense.bias]Loading weights:  36%|███▌      | 74/206 [00:00<00:00, 2546.65it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  36%|███▌      | 74/206 [00:00<00:00, 2541.40it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  36%|███▋      | 75/206 [00:00<00:00, 2565.89it/s, Materializing param=encoder.layer.4.attention.attention.key.bias]Loading weights:  36%|███▋      | 75/206 [00:00<00:00, 2560.58it/s, Materializing param=encoder.layer.4.attention.attention.key.bias]Loading weights:  37%|███▋      | 76/206 [00:00<00:00, 2584.33it/s, Materializing param=encoder.layer.4.attention.attention.key.weight]Loading weights:  37%|███▋      | 76/206 [00:00<00:00, 2578.21it/s, Materializing param=encoder.layer.4.attention.attention.key.weight]Loading weights:  37%|███▋      | 77/206 [00:00<00:00, 2601.67it/s, Materializing param=encoder.layer.4.attention.attention.query.bias]Loading weights:  37%|███▋      | 77/206 [00:00<00:00, 2596.32it/s, Materializing param=encoder.layer.4.attention.attention.query.bias]Loading weights:  38%|███▊      | 78/206 [00:00<00:00, 2619.68it/s, Materializing param=encoder.layer.4.attention.attention.query.weight]Loading weights:  38%|███▊      | 78/206 [00:00<00:00, 2614.36it/s, Materializing param=encoder.layer.4.attention.attention.query.weight]Loading weights:  38%|███▊      | 79/206 [00:00<00:00, 2637.63it/s, Materializing param=encoder.layer.4.attention.attention.value.bias]  Loading weights:  38%|███▊      | 79/206 [00:00<00:00, 2632.25it/s, Materializing param=encoder.layer.4.attention.attention.value.bias]Loading weights:  39%|███▉      | 80/206 [00:00<00:00, 2655.30it/s, Materializing param=encoder.layer.4.attention.attention.value.weight]Loading weights:  39%|███▉      | 80/206 [00:00<00:00, 2649.88it/s, Materializing param=encoder.layer.4.attention.attention.value.weight]Loading weights:  39%|███▉      | 81/206 [00:00<00:00, 2672.73it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]     Loading weights:  39%|███▉      | 81/206 [00:00<00:00, 2667.34it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]Loading weights:  40%|███▉      | 82/206 [00:00<00:00, 2689.41it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  40%|███▉      | 82/206 [00:00<00:00, 2684.06it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  40%|████      | 83/206 [00:00<00:00, 2706.57it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]      Loading weights:  40%|████      | 83/206 [00:00<00:00, 2701.28it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]Loading weights:  41%|████      | 84/206 [00:00<00:00, 2723.85it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  41%|████      | 84/206 [00:00<00:00, 2718.55it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  41%|████▏     | 85/206 [00:00<00:00, 2741.00it/s, Materializing param=encoder.layer.4.layernorm_after.bias]     Loading weights:  41%|████▏     | 85/206 [00:00<00:00, 2735.78it/s, Materializing param=encoder.layer.4.layernorm_after.bias]Loading weights:  42%|████▏     | 86/206 [00:00<00:00, 2758.38it/s, Materializing param=encoder.layer.4.layernorm_after.weight]Loading weights:  42%|████▏     | 86/206 [00:00<00:00, 2753.13it/s, Materializing param=encoder.layer.4.layernorm_after.weight]Loading weights:  42%|████▏     | 87/206 [00:00<00:00, 2775.59it/s, Materializing param=encoder.layer.4.layernorm_before.bias] Loading weights:  42%|████▏     | 87/206 [00:00<00:00, 2770.39it/s, Materializing param=encoder.layer.4.layernorm_before.bias]Loading weights:  43%|████▎     | 88/206 [00:00<00:00, 2791.93it/s, Materializing param=encoder.layer.4.layernorm_before.weight]Loading weights:  43%|████▎     | 88/206 [00:00<00:00, 2786.16it/s, Materializing param=encoder.layer.4.layernorm_before.weight]Loading weights:  43%|████▎     | 89/206 [00:00<00:00, 2808.13it/s, Materializing param=encoder.layer.4.output.dense.bias]      Loading weights:  43%|████▎     | 89/206 [00:00<00:00, 2802.92it/s, Materializing param=encoder.layer.4.output.dense.bias]Loading weights:  44%|████▎     | 90/206 [00:00<00:00, 2824.70it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  44%|████▎     | 90/206 [00:00<00:00, 2819.51it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  44%|████▍     | 91/206 [00:00<00:00, 2841.16it/s, Materializing param=encoder.layer.5.attention.attention.key.bias]Loading weights:  44%|████▍     | 91/206 [00:00<00:00, 2835.93it/s, Materializing param=encoder.layer.5.attention.attention.key.bias]Loading weights:  45%|████▍     | 92/206 [00:00<00:00, 2856.84it/s, Materializing param=encoder.layer.5.attention.attention.key.weight]Loading weights:  45%|████▍     | 92/206 [00:00<00:00, 2851.52it/s, Materializing param=encoder.layer.5.attention.attention.key.weight]Loading weights:  45%|████▌     | 93/206 [00:00<00:00, 2872.30it/s, Materializing param=encoder.layer.5.attention.attention.query.bias]Loading weights:  45%|████▌     | 93/206 [00:00<00:00, 2866.50it/s, Materializing param=encoder.layer.5.attention.attention.query.bias]Loading weights:  46%|████▌     | 94/206 [00:00<00:00, 2887.01it/s, Materializing param=encoder.layer.5.attention.attention.query.weight]Loading weights:  46%|████▌     | 94/206 [00:00<00:00, 2881.69it/s, Materializing param=encoder.layer.5.attention.attention.query.weight]Loading weights:  46%|████▌     | 95/206 [00:00<00:00, 2902.19it/s, Materializing param=encoder.layer.5.attention.attention.value.bias]  Loading weights:  46%|████▌     | 95/206 [00:00<00:00, 2896.81it/s, Materializing param=encoder.layer.5.attention.attention.value.bias]Loading weights:  47%|████▋     | 96/206 [00:00<00:00, 2917.14it/s, Materializing param=encoder.layer.5.attention.attention.value.weight]Loading weights:  47%|████▋     | 96/206 [00:00<00:00, 2911.83it/s, Materializing param=encoder.layer.5.attention.attention.value.weight]Loading weights:  47%|████▋     | 97/206 [00:00<00:00, 2932.04it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]     Loading weights:  47%|████▋     | 97/206 [00:00<00:00, 2926.73it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]Loading weights:  48%|████▊     | 98/206 [00:00<00:00, 2946.85it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  48%|████▊     | 98/206 [00:00<00:00, 2941.58it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  48%|████▊     | 99/206 [00:00<00:00, 2961.40it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]      Loading weights:  48%|████▊     | 99/206 [00:00<00:00, 2955.33it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]Loading weights:  49%|████▊     | 100/206 [00:00<00:00, 2975.21it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  49%|████▊     | 100/206 [00:00<00:00, 2969.92it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  49%|████▉     | 101/206 [00:00<00:00, 2989.74it/s, Materializing param=encoder.layer.5.layernorm_after.bias]     Loading weights:  49%|████▉     | 101/206 [00:00<00:00, 2984.49it/s, Materializing param=encoder.layer.5.layernorm_after.bias]Loading weights:  50%|████▉     | 102/206 [00:00<00:00, 3004.41it/s, Materializing param=encoder.layer.5.layernorm_after.weight]Loading weights:  50%|████▉     | 102/206 [00:00<00:00, 2998.85it/s, Materializing param=encoder.layer.5.layernorm_after.weight]Loading weights:  50%|█████     | 103/206 [00:00<00:00, 3018.52it/s, Materializing param=encoder.layer.5.layernorm_before.bias] Loading weights:  50%|█████     | 103/206 [00:00<00:00, 3013.21it/s, Materializing param=encoder.layer.5.layernorm_before.bias]Loading weights:  50%|█████     | 104/206 [00:00<00:00, 3032.74it/s, Materializing param=encoder.layer.5.layernorm_before.weight]Loading weights:  50%|█████     | 104/206 [00:00<00:00, 3027.47it/s, Materializing param=encoder.layer.5.layernorm_before.weight]Loading weights:  51%|█████     | 105/206 [00:00<00:00, 3046.31it/s, Materializing param=encoder.layer.5.output.dense.bias]      Loading weights:  51%|█████     | 105/206 [00:00<00:00, 3041.03it/s, Materializing param=encoder.layer.5.output.dense.bias]Loading weights:  51%|█████▏    | 106/206 [00:00<00:00, 3060.12it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  51%|█████▏    | 106/206 [00:00<00:00, 3054.91it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  52%|█████▏    | 107/206 [00:00<00:00, 3073.91it/s, Materializing param=encoder.layer.6.attention.attention.key.bias]Loading weights:  52%|█████▏    | 107/206 [00:00<00:00, 3068.42it/s, Materializing param=encoder.layer.6.attention.attention.key.bias]Loading weights:  52%|█████▏    | 108/206 [00:00<00:00, 3086.67it/s, Materializing param=encoder.layer.6.attention.attention.key.weight]Loading weights:  52%|█████▏    | 108/206 [00:00<00:00, 3081.32it/s, Materializing param=encoder.layer.6.attention.attention.key.weight]Loading weights:  53%|█████▎    | 109/206 [00:00<00:00, 3099.54it/s, Materializing param=encoder.layer.6.attention.attention.query.bias]Loading weights:  53%|█████▎    | 109/206 [00:00<00:00, 3094.23it/s, Materializing param=encoder.layer.6.attention.attention.query.bias]Loading weights:  53%|█████▎    | 110/206 [00:00<00:00, 3112.47it/s, Materializing param=encoder.layer.6.attention.attention.query.weight]Loading weights:  53%|█████▎    | 110/206 [00:00<00:00, 3107.06it/s, Materializing param=encoder.layer.6.attention.attention.query.weight]Loading weights:  54%|█████▍    | 111/206 [00:00<00:00, 3124.32it/s, Materializing param=encoder.layer.6.attention.attention.value.bias]  Loading weights:  54%|█████▍    | 111/206 [00:00<00:00, 3118.90it/s, Materializing param=encoder.layer.6.attention.attention.value.bias]Loading weights:  54%|█████▍    | 112/206 [00:00<00:00, 3136.66it/s, Materializing param=encoder.layer.6.attention.attention.value.weight]Loading weights:  54%|█████▍    | 112/206 [00:00<00:00, 3131.29it/s, Materializing param=encoder.layer.6.attention.attention.value.weight]Loading weights:  55%|█████▍    | 113/206 [00:00<00:00, 3148.94it/s, Materializing param=encoder.layer.6.attention.output.dense.bias]     Loading weights:  55%|█████▍    | 113/206 [00:00<00:00, 3143.66it/s, Materializing param=encoder.layer.6.attention.output.dense.bias]Loading weights:  55%|█████▌    | 114/206 [00:00<00:00, 3161.18it/s, Materializing param=encoder.layer.6.attention.output.dense.weight]Loading weights:  55%|█████▌    | 114/206 [00:00<00:00, 3155.84it/s, Materializing param=encoder.layer.6.attention.output.dense.weight]Loading weights:  56%|█████▌    | 115/206 [00:00<00:00, 3173.38it/s, Materializing param=encoder.layer.6.intermediate.dense.bias]      Loading weights:  56%|█████▌    | 115/206 [00:00<00:00, 3168.11it/s, Materializing param=encoder.layer.6.intermediate.dense.bias]Loading weights:  56%|█████▋    | 116/206 [00:00<00:00, 3185.74it/s, Materializing param=encoder.layer.6.intermediate.dense.weight]Loading weights:  56%|█████▋    | 116/206 [00:00<00:00, 3179.54it/s, Materializing param=encoder.layer.6.intermediate.dense.weight]Loading weights:  57%|█████▋    | 117/206 [00:00<00:00, 3196.82it/s, Materializing param=encoder.layer.6.layernorm_after.bias]     Loading weights:  57%|█████▋    | 117/206 [00:00<00:00, 3191.60it/s, Materializing param=encoder.layer.6.layernorm_after.bias]Loading weights:  57%|█████▋    | 118/206 [00:00<00:00, 3209.36it/s, Materializing param=encoder.layer.6.layernorm_after.weight]Loading weights:  57%|█████▋    | 118/206 [00:00<00:00, 3204.18it/s, Materializing param=encoder.layer.6.layernorm_after.weight]Loading weights:  58%|█████▊    | 119/206 [00:00<00:00, 3221.87it/s, Materializing param=encoder.layer.6.layernorm_before.bias] Loading weights:  58%|█████▊    | 119/206 [00:00<00:00, 3216.66it/s, Materializing param=encoder.layer.6.layernorm_before.bias]Loading weights:  58%|█████▊    | 120/206 [00:00<00:00, 3234.20it/s, Materializing param=encoder.layer.6.layernorm_before.weight]Loading weights:  58%|█████▊    | 120/206 [00:00<00:00, 3229.06it/s, Materializing param=encoder.layer.6.layernorm_before.weight]Loading weights:  59%|█████▊    | 121/206 [00:00<00:00, 3246.45it/s, Materializing param=encoder.layer.6.output.dense.bias]      Loading weights:  59%|█████▊    | 121/206 [00:00<00:00, 3241.35it/s, Materializing param=encoder.layer.6.output.dense.bias]Loading weights:  59%|█████▉    | 122/206 [00:00<00:00, 3257.92it/s, Materializing param=encoder.layer.6.output.dense.weight]Loading weights:  59%|█████▉    | 122/206 [00:00<00:00, 3252.74it/s, Materializing param=encoder.layer.6.output.dense.weight]Loading weights:  60%|█████▉    | 123/206 [00:00<00:00, 3269.68it/s, Materializing param=encoder.layer.7.attention.attention.key.bias]Loading weights:  60%|█████▉    | 123/206 [00:00<00:00, 3264.40it/s, Materializing param=encoder.layer.7.attention.attention.key.bias]Loading weights:  60%|██████    | 124/206 [00:00<00:00, 3280.77it/s, Materializing param=encoder.layer.7.attention.attention.key.weight]Loading weights:  60%|██████    | 124/206 [00:00<00:00, 3275.50it/s, Materializing param=encoder.layer.7.attention.attention.key.weight]Loading weights:  61%|██████    | 125/206 [00:00<00:00, 3291.76it/s, Materializing param=encoder.layer.7.attention.attention.query.bias]Loading weights:  61%|██████    | 125/206 [00:00<00:00, 3286.41it/s, Materializing param=encoder.layer.7.attention.attention.query.bias]Loading weights:  61%|██████    | 126/206 [00:00<00:00, 3302.64it/s, Materializing param=encoder.layer.7.attention.attention.query.weight]Loading weights:  61%|██████    | 126/206 [00:00<00:00, 3297.33it/s, Materializing param=encoder.layer.7.attention.attention.query.weight]Loading weights:  62%|██████▏   | 127/206 [00:00<00:00, 3313.41it/s, Materializing param=encoder.layer.7.attention.attention.value.bias]  Loading weights:  62%|██████▏   | 127/206 [00:00<00:00, 3308.12it/s, Materializing param=encoder.layer.7.attention.attention.value.bias]Loading weights:  62%|██████▏   | 128/206 [00:00<00:00, 3323.39it/s, Materializing param=encoder.layer.7.attention.attention.value.weight]Loading weights:  62%|██████▏   | 128/206 [00:00<00:00, 3318.05it/s, Materializing param=encoder.layer.7.attention.attention.value.weight]Loading weights:  63%|██████▎   | 129/206 [00:00<00:00, 3333.90it/s, Materializing param=encoder.layer.7.attention.output.dense.bias]     Loading weights:  63%|██████▎   | 129/206 [00:00<00:00, 3328.73it/s, Materializing param=encoder.layer.7.attention.output.dense.bias]Loading weights:  63%|██████▎   | 130/206 [00:00<00:00, 3344.60it/s, Materializing param=encoder.layer.7.attention.output.dense.weight]Loading weights:  63%|██████▎   | 130/206 [00:00<00:00, 3339.39it/s, Materializing param=encoder.layer.7.attention.output.dense.weight]Loading weights:  64%|██████▎   | 131/206 [00:00<00:00, 3354.58it/s, Materializing param=encoder.layer.7.intermediate.dense.bias]      Loading weights:  64%|██████▎   | 131/206 [00:00<00:00, 3349.39it/s, Materializing param=encoder.layer.7.intermediate.dense.bias]Loading weights:  64%|██████▍   | 132/206 [00:00<00:00, 3365.21it/s, Materializing param=encoder.layer.7.intermediate.dense.weight]Loading weights:  64%|██████▍   | 132/206 [00:00<00:00, 3359.98it/s, Materializing param=encoder.layer.7.intermediate.dense.weight]Loading weights:  65%|██████▍   | 133/206 [00:00<00:00, 3375.83it/s, Materializing param=encoder.layer.7.layernorm_after.bias]     Loading weights:  65%|██████▍   | 133/206 [00:00<00:00, 3370.14it/s, Materializing param=encoder.layer.7.layernorm_after.bias]Loading weights:  65%|██████▌   | 134/206 [00:00<00:00, 3385.93it/s, Materializing param=encoder.layer.7.layernorm_after.weight]Loading weights:  65%|██████▌   | 134/206 [00:00<00:00, 3380.81it/s, Materializing param=encoder.layer.7.layernorm_after.weight]Loading weights:  66%|██████▌   | 135/206 [00:00<00:00, 3396.69it/s, Materializing param=encoder.layer.7.layernorm_before.bias] Loading weights:  66%|██████▌   | 135/206 [00:00<00:00, 3391.64it/s, Materializing param=encoder.layer.7.layernorm_before.bias]Loading weights:  66%|██████▌   | 136/206 [00:00<00:00, 3407.52it/s, Materializing param=encoder.layer.7.layernorm_before.weight]Loading weights:  66%|██████▌   | 136/206 [00:00<00:00, 3402.46it/s, Materializing param=encoder.layer.7.layernorm_before.weight]Loading weights:  67%|██████▋   | 137/206 [00:00<00:00, 3418.14it/s, Materializing param=encoder.layer.7.output.dense.bias]      Loading weights:  67%|██████▋   | 137/206 [00:00<00:00, 3413.12it/s, Materializing param=encoder.layer.7.output.dense.bias]Loading weights:  67%|██████▋   | 138/206 [00:00<00:00, 3428.44it/s, Materializing param=encoder.layer.7.output.dense.weight]Loading weights:  67%|██████▋   | 138/206 [00:00<00:00, 3423.40it/s, Materializing param=encoder.layer.7.output.dense.weight]Loading weights:  67%|██████▋   | 139/206 [00:00<00:00, 3438.72it/s, Materializing param=encoder.layer.8.attention.attention.key.bias]Loading weights:  67%|██████▋   | 139/206 [00:00<00:00, 3433.01it/s, Materializing param=encoder.layer.8.attention.attention.key.bias]Loading weights:  68%|██████▊   | 140/206 [00:00<00:00, 3447.72it/s, Materializing param=encoder.layer.8.attention.attention.key.weight]Loading weights:  68%|██████▊   | 140/206 [00:00<00:00, 3442.43it/s, Materializing param=encoder.layer.8.attention.attention.key.weight]Loading weights:  68%|██████▊   | 141/206 [00:00<00:00, 3457.05it/s, Materializing param=encoder.layer.8.attention.attention.query.bias]Loading weights:  68%|██████▊   | 141/206 [00:00<00:00, 3451.88it/s, Materializing param=encoder.layer.8.attention.attention.query.bias]Loading weights:  69%|██████▉   | 142/206 [00:00<00:00, 3466.57it/s, Materializing param=encoder.layer.8.attention.attention.query.weight]Loading weights:  69%|██████▉   | 142/206 [00:00<00:00, 3461.41it/s, Materializing param=encoder.layer.8.attention.attention.query.weight]Loading weights:  69%|██████▉   | 143/206 [00:00<00:00, 3475.95it/s, Materializing param=encoder.layer.8.attention.attention.value.bias]  Loading weights:  69%|██████▉   | 143/206 [00:00<00:00, 3470.80it/s, Materializing param=encoder.layer.8.attention.attention.value.bias]Loading weights:  70%|██████▉   | 144/206 [00:00<00:00, 3485.33it/s, Materializing param=encoder.layer.8.attention.attention.value.weight]Loading weights:  70%|██████▉   | 144/206 [00:00<00:00, 3479.79it/s, Materializing param=encoder.layer.8.attention.attention.value.weight]Loading weights:  70%|███████   | 145/206 [00:00<00:00, 3493.41it/s, Materializing param=encoder.layer.8.attention.output.dense.bias]     Loading weights:  70%|███████   | 145/206 [00:00<00:00, 3488.30it/s, Materializing param=encoder.layer.8.attention.output.dense.bias]Loading weights:  71%|███████   | 146/206 [00:00<00:00, 3502.51it/s, Materializing param=encoder.layer.8.attention.output.dense.weight]Loading weights:  71%|███████   | 146/206 [00:00<00:00, 3497.45it/s, Materializing param=encoder.layer.8.attention.output.dense.weight]Loading weights:  71%|███████▏  | 147/206 [00:00<00:00, 3511.76it/s, Materializing param=encoder.layer.8.intermediate.dense.bias]      Loading weights:  71%|███████▏  | 147/206 [00:00<00:00, 3506.74it/s, Materializing param=encoder.layer.8.intermediate.dense.bias]Loading weights:  72%|███████▏  | 148/206 [00:00<00:00, 3521.09it/s, Materializing param=encoder.layer.8.intermediate.dense.weight]Loading weights:  72%|███████▏  | 148/206 [00:00<00:00, 3515.96it/s, Materializing param=encoder.layer.8.intermediate.dense.weight]Loading weights:  72%|███████▏  | 149/206 [00:00<00:00, 3530.24it/s, Materializing param=encoder.layer.8.layernorm_after.bias]     Loading weights:  72%|███████▏  | 149/206 [00:00<00:00, 3525.24it/s, Materializing param=encoder.layer.8.layernorm_after.bias]Loading weights:  73%|███████▎  | 150/206 [00:00<00:00, 3539.74it/s, Materializing param=encoder.layer.8.layernorm_after.weight]Loading weights:  73%|███████▎  | 150/206 [00:00<00:00, 3534.27it/s, Materializing param=encoder.layer.8.layernorm_after.weight]Loading weights:  73%|███████▎  | 151/206 [00:00<00:00, 3548.72it/s, Materializing param=encoder.layer.8.layernorm_before.bias] Loading weights:  73%|███████▎  | 151/206 [00:00<00:00, 3543.77it/s, Materializing param=encoder.layer.8.layernorm_before.bias]Loading weights:  74%|███████▍  | 152/206 [00:00<00:00, 3558.26it/s, Materializing param=encoder.layer.8.layernorm_before.weight]Loading weights:  74%|███████▍  | 152/206 [00:00<00:00, 3553.35it/s, Materializing param=encoder.layer.8.layernorm_before.weight]Loading weights:  74%|███████▍  | 153/206 [00:00<00:00, 3567.77it/s, Materializing param=encoder.layer.8.output.dense.bias]      Loading weights:  74%|███████▍  | 153/206 [00:00<00:00, 3562.82it/s, Materializing param=encoder.layer.8.output.dense.bias]Loading weights:  75%|███████▍  | 154/206 [00:00<00:00, 3576.91it/s, Materializing param=encoder.layer.8.output.dense.weight]Loading weights:  75%|███████▍  | 154/206 [00:00<00:00, 3572.01it/s, Materializing param=encoder.layer.8.output.dense.weight]Loading weights:  75%|███████▌  | 155/206 [00:00<00:00, 3585.96it/s, Materializing param=encoder.layer.9.attention.attention.key.bias]Loading weights:  75%|███████▌  | 155/206 [00:00<00:00, 3580.89it/s, Materializing param=encoder.layer.9.attention.attention.key.bias]Loading weights:  76%|███████▌  | 156/206 [00:00<00:00, 3594.35it/s, Materializing param=encoder.layer.9.attention.attention.key.weight]Loading weights:  76%|███████▌  | 156/206 [00:00<00:00, 3588.53it/s, Materializing param=encoder.layer.9.attention.attention.key.weight]Loading weights:  76%|███████▌  | 157/206 [00:00<00:00, 3601.74it/s, Materializing param=encoder.layer.9.attention.attention.query.bias]Loading weights:  76%|███████▌  | 157/206 [00:00<00:00, 3596.72it/s, Materializing param=encoder.layer.9.attention.attention.query.bias]Loading weights:  77%|███████▋  | 158/206 [00:00<00:00, 3610.15it/s, Materializing param=encoder.layer.9.attention.attention.query.weight]Loading weights:  77%|███████▋  | 158/206 [00:00<00:00, 3604.78it/s, Materializing param=encoder.layer.9.attention.attention.query.weight]Loading weights:  77%|███████▋  | 159/206 [00:00<00:00, 3618.00it/s, Materializing param=encoder.layer.9.attention.attention.value.bias]  Loading weights:  77%|███████▋  | 159/206 [00:00<00:00, 3613.02it/s, Materializing param=encoder.layer.9.attention.attention.value.bias]Loading weights:  78%|███████▊  | 160/206 [00:00<00:00, 3625.96it/s, Materializing param=encoder.layer.9.attention.attention.value.weight]Loading weights:  78%|███████▊  | 160/206 [00:00<00:00, 3620.91it/s, Materializing param=encoder.layer.9.attention.attention.value.weight]Loading weights:  78%|███████▊  | 161/206 [00:00<00:00, 3633.97it/s, Materializing param=encoder.layer.9.attention.output.dense.bias]     Loading weights:  78%|███████▊  | 161/206 [00:00<00:00, 3628.93it/s, Materializing param=encoder.layer.9.attention.output.dense.bias]Loading weights:  79%|███████▊  | 162/206 [00:00<00:00, 3641.24it/s, Materializing param=encoder.layer.9.attention.output.dense.weight]Loading weights:  79%|███████▊  | 162/206 [00:00<00:00, 3636.17it/s, Materializing param=encoder.layer.9.attention.output.dense.weight]Loading weights:  79%|███████▉  | 163/206 [00:00<00:00, 3649.13it/s, Materializing param=encoder.layer.9.intermediate.dense.bias]      Loading weights:  79%|███████▉  | 163/206 [00:00<00:00, 3644.23it/s, Materializing param=encoder.layer.9.intermediate.dense.bias]Loading weights:  80%|███████▉  | 164/206 [00:00<00:00, 3657.32it/s, Materializing param=encoder.layer.9.intermediate.dense.weight]Loading weights:  80%|███████▉  | 164/206 [00:00<00:00, 3652.41it/s, Materializing param=encoder.layer.9.intermediate.dense.weight]Loading weights:  80%|████████  | 165/206 [00:00<00:00, 3665.36it/s, Materializing param=encoder.layer.9.layernorm_after.bias]     Loading weights:  80%|████████  | 165/206 [00:00<00:00, 3660.49it/s, Materializing param=encoder.layer.9.layernorm_after.bias]Loading weights:  81%|████████  | 166/206 [00:00<00:00, 3673.74it/s, Materializing param=encoder.layer.9.layernorm_after.weight]Loading weights:  81%|████████  | 166/206 [00:00<00:00, 3668.84it/s, Materializing param=encoder.layer.9.layernorm_after.weight]Loading weights:  81%|████████  | 167/206 [00:00<00:00, 3682.08it/s, Materializing param=encoder.layer.9.layernorm_before.bias] Loading weights:  81%|████████  | 167/206 [00:00<00:00, 3677.28it/s, Materializing param=encoder.layer.9.layernorm_before.bias]Loading weights:  82%|████████▏ | 168/206 [00:00<00:00, 3689.91it/s, Materializing param=encoder.layer.9.layernorm_before.weight]Loading weights:  82%|████████▏ | 168/206 [00:00<00:00, 3685.08it/s, Materializing param=encoder.layer.9.layernorm_before.weight]Loading weights:  82%|████████▏ | 169/206 [00:00<00:00, 3698.31it/s, Materializing param=encoder.layer.9.output.dense.bias]      Loading weights:  82%|████████▏ | 169/206 [00:00<00:00, 3693.53it/s, Materializing param=encoder.layer.9.output.dense.bias]Loading weights:  83%|████████▎ | 170/206 [00:00<00:00, 3706.41it/s, Materializing param=encoder.layer.9.output.dense.weight]Loading weights:  83%|████████▎ | 170/206 [00:00<00:00, 3701.60it/s, Materializing param=encoder.layer.9.output.dense.weight]Loading weights:  83%|████████▎ | 171/206 [00:00<00:00, 3714.43it/s, Materializing param=encoder.layer.10.attention.attention.key.bias]Loading weights:  83%|████████▎ | 171/206 [00:00<00:00, 3709.53it/s, Materializing param=encoder.layer.10.attention.attention.key.bias]Loading weights:  83%|████████▎ | 172/206 [00:00<00:00, 3721.77it/s, Materializing param=encoder.layer.10.attention.attention.key.weight]Loading weights:  83%|████████▎ | 172/206 [00:00<00:00, 3716.52it/s, Materializing param=encoder.layer.10.attention.attention.key.weight]Loading weights:  84%|████████▍ | 173/206 [00:00<00:00, 3728.56it/s, Materializing param=encoder.layer.10.attention.attention.query.bias]Loading weights:  84%|████████▍ | 173/206 [00:00<00:00, 3723.07it/s, Materializing param=encoder.layer.10.attention.attention.query.bias]Loading weights:  84%|████████▍ | 174/206 [00:00<00:00, 3735.10it/s, Materializing param=encoder.layer.10.attention.attention.query.weight]Loading weights:  84%|████████▍ | 174/206 [00:00<00:00, 3730.18it/s, Materializing param=encoder.layer.10.attention.attention.query.weight]Loading weights:  85%|████████▍ | 175/206 [00:00<00:00, 3742.20it/s, Materializing param=encoder.layer.10.attention.attention.value.bias]  Loading weights:  85%|████████▍ | 175/206 [00:00<00:00, 3737.27it/s, Materializing param=encoder.layer.10.attention.attention.value.bias]Loading weights:  85%|████████▌ | 176/206 [00:00<00:00, 3749.27it/s, Materializing param=encoder.layer.10.attention.attention.value.weight]Loading weights:  85%|████████▌ | 176/206 [00:00<00:00, 3744.40it/s, Materializing param=encoder.layer.10.attention.attention.value.weight]Loading weights:  86%|████████▌ | 177/206 [00:00<00:00, 3756.45it/s, Materializing param=encoder.layer.10.attention.output.dense.bias]     Loading weights:  86%|████████▌ | 177/206 [00:00<00:00, 3751.61it/s, Materializing param=encoder.layer.10.attention.output.dense.bias]Loading weights:  86%|████████▋ | 178/206 [00:00<00:00, 3763.51it/s, Materializing param=encoder.layer.10.attention.output.dense.weight]Loading weights:  86%|████████▋ | 178/206 [00:00<00:00, 3758.70it/s, Materializing param=encoder.layer.10.attention.output.dense.weight]Loading weights:  87%|████████▋ | 179/206 [00:00<00:00, 3769.98it/s, Materializing param=encoder.layer.10.intermediate.dense.bias]      Loading weights:  87%|████████▋ | 179/206 [00:00<00:00, 3765.18it/s, Materializing param=encoder.layer.10.intermediate.dense.bias]Loading weights:  87%|████████▋ | 180/206 [00:00<00:00, 3777.23it/s, Materializing param=encoder.layer.10.intermediate.dense.weight]Loading weights:  87%|████████▋ | 180/206 [00:00<00:00, 3772.48it/s, Materializing param=encoder.layer.10.intermediate.dense.weight]Loading weights:  88%|████████▊ | 181/206 [00:00<00:00, 3784.47it/s, Materializing param=encoder.layer.10.layernorm_after.bias]     Loading weights:  88%|████████▊ | 181/206 [00:00<00:00, 3779.76it/s, Materializing param=encoder.layer.10.layernorm_after.bias]Loading weights:  88%|████████▊ | 182/206 [00:00<00:00, 3791.96it/s, Materializing param=encoder.layer.10.layernorm_after.weight]Loading weights:  88%|████████▊ | 182/206 [00:00<00:00, 3787.29it/s, Materializing param=encoder.layer.10.layernorm_after.weight]Loading weights:  89%|████████▉ | 183/206 [00:00<00:00, 3799.51it/s, Materializing param=encoder.layer.10.layernorm_before.bias] Loading weights:  89%|████████▉ | 183/206 [00:00<00:00, 3794.85it/s, Materializing param=encoder.layer.10.layernorm_before.bias]Loading weights:  89%|████████▉ | 184/206 [00:00<00:00, 3807.08it/s, Materializing param=encoder.layer.10.layernorm_before.weight]Loading weights:  89%|████████▉ | 184/206 [00:00<00:00, 3802.45it/s, Materializing param=encoder.layer.10.layernorm_before.weight]Loading weights:  90%|████████▉ | 185/206 [00:00<00:00, 3814.09it/s, Materializing param=encoder.layer.10.output.dense.bias]      Loading weights:  90%|████████▉ | 185/206 [00:00<00:00, 3809.02it/s, Materializing param=encoder.layer.10.output.dense.bias]Loading weights:  90%|█████████ | 186/206 [00:00<00:00, 3820.77it/s, Materializing param=encoder.layer.10.output.dense.weight]Loading weights:  90%|█████████ | 186/206 [00:00<00:00, 3816.17it/s, Materializing param=encoder.layer.10.output.dense.weight]Loading weights:  91%|█████████ | 187/206 [00:00<00:00, 3828.02it/s, Materializing param=encoder.layer.11.attention.attention.key.bias]Loading weights:  91%|█████████ | 187/206 [00:00<00:00, 3823.28it/s, Materializing param=encoder.layer.11.attention.attention.key.bias]Loading weights:  91%|█████████▏| 188/206 [00:00<00:00, 3834.57it/s, Materializing param=encoder.layer.11.attention.attention.key.weight]Loading weights:  91%|█████████▏| 188/206 [00:00<00:00, 3829.82it/s, Materializing param=encoder.layer.11.attention.attention.key.weight]Loading weights:  92%|█████████▏| 189/206 [00:00<00:00, 3841.14it/s, Materializing param=encoder.layer.11.attention.attention.query.bias]Loading weights:  92%|█████████▏| 189/206 [00:00<00:00, 3836.42it/s, Materializing param=encoder.layer.11.attention.attention.query.bias]Loading weights:  92%|█████████▏| 190/206 [00:00<00:00, 3847.71it/s, Materializing param=encoder.layer.11.attention.attention.query.weight]Loading weights:  92%|█████████▏| 190/206 [00:00<00:00, 3842.44it/s, Materializing param=encoder.layer.11.attention.attention.query.weight]Loading weights:  93%|█████████▎| 191/206 [00:00<00:00, 3853.59it/s, Materializing param=encoder.layer.11.attention.attention.value.bias]  Loading weights:  93%|█████████▎| 191/206 [00:00<00:00, 3848.82it/s, Materializing param=encoder.layer.11.attention.attention.value.bias]Loading weights:  93%|█████████▎| 192/206 [00:00<00:00, 3860.08it/s, Materializing param=encoder.layer.11.attention.attention.value.weight]Loading weights:  93%|█████████▎| 192/206 [00:00<00:00, 3855.39it/s, Materializing param=encoder.layer.11.attention.attention.value.weight]Loading weights:  94%|█████████▎| 193/206 [00:00<00:00, 3866.59it/s, Materializing param=encoder.layer.11.attention.output.dense.bias]     Loading weights:  94%|█████████▎| 193/206 [00:00<00:00, 3861.88it/s, Materializing param=encoder.layer.11.attention.output.dense.bias]Loading weights:  94%|█████████▍| 194/206 [00:00<00:00, 3872.95it/s, Materializing param=encoder.layer.11.attention.output.dense.weight]Loading weights:  94%|█████████▍| 194/206 [00:00<00:00, 3868.31it/s, Materializing param=encoder.layer.11.attention.output.dense.weight]Loading weights:  95%|█████████▍| 195/206 [00:00<00:00, 3879.36it/s, Materializing param=encoder.layer.11.intermediate.dense.bias]      Loading weights:  95%|█████████▍| 195/206 [00:00<00:00, 3874.77it/s, Materializing param=encoder.layer.11.intermediate.dense.bias]Loading weights:  95%|█████████▌| 196/206 [00:00<00:00, 3885.34it/s, Materializing param=encoder.layer.11.intermediate.dense.weight]Loading weights:  95%|█████████▌| 196/206 [00:00<00:00, 3880.64it/s, Materializing param=encoder.layer.11.intermediate.dense.weight]Loading weights:  96%|█████████▌| 197/206 [00:00<00:00, 3891.66it/s, Materializing param=encoder.layer.11.layernorm_after.bias]     Loading weights:  96%|█████████▌| 197/206 [00:00<00:00, 3887.10it/s, Materializing param=encoder.layer.11.layernorm_after.bias]Loading weights:  96%|█████████▌| 198/206 [00:00<00:00, 3898.38it/s, Materializing param=encoder.layer.11.layernorm_after.weight]Loading weights:  96%|█████████▌| 198/206 [00:00<00:00, 3893.78it/s, Materializing param=encoder.layer.11.layernorm_after.weight]Loading weights:  97%|█████████▋| 199/206 [00:00<00:00, 3904.58it/s, Materializing param=encoder.layer.11.layernorm_before.bias] Loading weights:  97%|█████████▋| 199/206 [00:00<00:00, 3899.98it/s, Materializing param=encoder.layer.11.layernorm_before.bias]Loading weights:  97%|█████████▋| 200/206 [00:00<00:00, 3911.19it/s, Materializing param=encoder.layer.11.layernorm_before.weight]Loading weights:  97%|█████████▋| 200/206 [00:00<00:00, 3906.66it/s, Materializing param=encoder.layer.11.layernorm_before.weight]Loading weights:  98%|█████████▊| 201/206 [00:00<00:00, 3917.94it/s, Materializing param=encoder.layer.11.output.dense.bias]      Loading weights:  98%|█████████▊| 201/206 [00:00<00:00, 3913.49it/s, Materializing param=encoder.layer.11.output.dense.bias]Loading weights:  98%|█████████▊| 202/206 [00:00<00:00, 3923.94it/s, Materializing param=encoder.layer.11.output.dense.weight]Loading weights:  98%|█████████▊| 202/206 [00:00<00:00, 3919.44it/s, Materializing param=encoder.layer.11.output.dense.weight]Loading weights:  99%|█████████▊| 203/206 [00:00<00:00, 3930.33it/s, Materializing param=layernorm.bias]                      Loading weights:  99%|█████████▊| 203/206 [00:00<00:00, 3926.02it/s, Materializing param=layernorm.bias]Loading weights:  99%|█████████▉| 204/206 [00:00<00:00, 3937.81it/s, Materializing param=layernorm.weight]Loading weights:  99%|█████████▉| 204/206 [00:00<00:00, 3933.50it/s, Materializing param=layernorm.weight]Loading weights: 100%|█████████▉| 205/206 [00:00<00:00, 3945.43it/s, Materializing param=pooler.dense.bias]Loading weights: 100%|█████████▉| 205/206 [00:00<00:00, 3941.15it/s, Materializing param=pooler.dense.bias]Loading weights: 100%|██████████| 206/206 [00:00<00:00, 3952.69it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|██████████| 206/206 [00:00<00:00, 3948.45it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|██████████| 206/206 [00:00<00:00, 3939.70it/s, Materializing param=pooler.dense.weight]
ViltModel LOAD REPORT from: dandelin/vilt-b32-mlm
Key                                          | Status     |  | 
---------------------------------------------+------------+--+-
vilt.embeddings.text_embeddings.position_ids | UNEXPECTED |  | 
mlm_score.decoder.weight                     | UNEXPECTED |  | 
mlm_score.bias                               | UNEXPECTED |  | 
mlm_score.transform.LayerNorm.weight         | UNEXPECTED |  | 
mlm_score.transform.dense.bias               | UNEXPECTED |  | 
mlm_score.transform.LayerNorm.bias           | UNEXPECTED |  | 
mlm_score.transform.dense.weight             | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
/home/zhisheng/stats507/train/run_finetune.py:158: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=args.use_amp)
2025-12-02 10:40:53 - INFO - train - Epoch 1/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 10:56:52 - INFO - train - Train metrics: {
  "accuracy": 0.6934117647058824,
  "auroc": 0.7031447551144642,
  "macro_f1": 0.6154100977394149,
  "loss": 0.5860987100040211
}
2025-12-02 10:58:34 - INFO - train - Val metrics: {
  "accuracy": 0.6173076923076923,
  "auroc": 0.6494976817531906,
  "macro_f1": 0.593032630539857,
  "loss": 0.664592052423037
}
2025-12-02 10:58:40 - INFO - train - Saved new best checkpoint with AUROC=0.6495
2025-12-02 10:58:40 - INFO - train - Epoch 2/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 11:14:04 - INFO - train - Train metrics: {
  "accuracy": 0.8110588235294117,
  "auroc": 0.8670455660038874,
  "macro_f1": 0.7869755167439334,
  "loss": 0.4303930953530704
}
2025-12-02 11:15:50 - INFO - train - Val metrics: {
  "accuracy": 0.6432692307692308,
  "auroc": 0.6797424086376858,
  "macro_f1": 0.5962221698977055,
  "loss": 0.7837146648993859
}
2025-12-02 11:15:56 - INFO - train - Saved new best checkpoint with AUROC=0.6797
2025-12-02 11:15:56 - INFO - train - Epoch 3/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 11:31:10 - INFO - train - Train metrics: {
  "accuracy": 0.916,
  "auroc": 0.9685587339297748,
  "macro_f1": 0.9077209174009613,
  "loss": 0.21763348646724925
}
2025-12-02 11:32:49 - INFO - train - Val metrics: {
  "accuracy": 0.6826923076923077,
  "auroc": 0.7228667036378933,
  "macro_f1": 0.6466867618718188,
  "loss": 1.0920777330031761
}
2025-12-02 11:32:55 - INFO - train - Saved new best checkpoint with AUROC=0.7229
2025-12-02 11:32:55 - INFO - train - Epoch 4/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 11:47:51 - INFO - train - Train metrics: {
  "accuracy": 0.9678823529411764,
  "auroc": 0.9935595210749122,
  "macro_f1": 0.9648806976641238,
  "loss": 0.10445346748127657
}
2025-12-02 11:49:38 - INFO - train - Val metrics: {
  "accuracy": 0.6807692307692308,
  "auroc": 0.707319925604838,
  "macro_f1": 0.6580627782795392,
  "loss": 1.5727292372630193
}
2025-12-02 11:49:38 - INFO - train - Epoch 5/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 12:05:07 - INFO - train - Train metrics: {
  "accuracy": 0.9870588235294118,
  "auroc": 0.9988230895987518,
  "macro_f1": 0.9858694826223653,
  "loss": 0.043222203422995174
}
2025-12-02 12:06:53 - INFO - train - Val metrics: {
  "accuracy": 0.675,
  "auroc": 0.7158572608848195,
  "macro_f1": 0.6441975618544805,
  "loss": 2.14246983894935
}
2025-12-02 12:06:53 - INFO - train - Epoch 6/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 12:22:05 - INFO - train - Train metrics: {
  "accuracy": 0.9938823529411764,
  "auroc": 0.99971236719532,
  "macro_f1": 0.9933201190578455,
  "loss": 0.02090547734148362
}
2025-12-02 12:23:47 - INFO - train - Val metrics: {
  "accuracy": 0.6884615384615385,
  "auroc": 0.7145972211218881,
  "macro_f1": 0.6644880694920722,
  "loss": 2.2123926107700056
}
2025-12-02 12:23:47 - INFO - train - Epoch 7/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 12:39:22 - INFO - train - Train metrics: {
  "accuracy": 0.9977647058823529,
  "auroc": 0.9999783950566923,
  "macro_f1": 0.9975598195874142,
  "loss": 0.00707819530543159
}
2025-12-02 12:41:09 - INFO - train - Val metrics: {
  "accuracy": 0.676923076923077,
  "auroc": 0.7083988818090248,
  "macro_f1": 0.6528249698963959,
  "loss": 2.5599259193126973
}
2025-12-02 12:41:09 - INFO - train - Epoch 8/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 12:57:03 - INFO - train - Train metrics: {
  "accuracy": 0.9991764705882353,
  "auroc": 0.9999970387630153,
  "macro_f1": 0.9991009861637843,
  "loss": 0.001991458345861996
}
2025-12-02 12:58:50 - INFO - train - Val metrics: {
  "accuracy": 0.6884615384615385,
  "auroc": 0.7203126709447656,
  "macro_f1": 0.6614025426964802,
  "loss": 2.6950895419487586
}
2025-12-02 12:58:50 - INFO - train - Epoch 9/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 13:14:28 - INFO - train - Train metrics: {
  "accuracy": 0.9998823529411764,
  "auroc": 0.9999999395665922,
  "macro_f1": 0.9998715694519692,
  "loss": 0.00048718550625969384
}
2025-12-02 13:16:11 - INFO - train - Val metrics: {
  "accuracy": 0.6711538461538461,
  "auroc": 0.7121884325331704,
  "macro_f1": 0.636287779318469,
  "loss": 2.96668261381296
}
2025-12-02 13:16:11 - INFO - train - Epoch 10/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 13:30:58 - INFO - train - Train metrics: {
  "accuracy": 1.0,
  "auroc": 1.0,
  "macro_f1": 1.0,
  "loss": 9.087639696457807e-05
}
2025-12-02 13:32:39 - INFO - train - Val metrics: {
  "accuracy": 0.6865384615384615,
  "auroc": 0.7131768469579849,
  "macro_f1": 0.6580879386849536,
  "loss": 2.8606343489426833
}
2025-12-02 13:32:39 - INFO - train - Evaluating best checkpoint on test split.
2025-12-02 13:38:07 - INFO - train - Test metrics: {
  "accuracy": 0.6956666666666667,
  "auroc": 0.7497227822580645,
  "macro_f1": 0.6536407866742118,
  "loss": 0.9844966442386309
}
2025-12-02 13:38:07 - INFO - train - Saved test predictions to logs/predictions/vilt_v2/test_predictions.csv
2025-12-02 13:38:26 - INFO - train - Using device cuda
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]Loading weights:   1%|          | 1/199 [00:00<00:00, 17189.77it/s, Materializing param=bert.embeddings.LayerNorm.bias]Loading weights:   1%|          | 1/199 [00:00<00:17, 11.35it/s, Materializing param=bert.embeddings.LayerNorm.bias]   Loading weights:   1%|          | 2/199 [00:00<00:08, 22.65it/s, Materializing param=bert.embeddings.LayerNorm.weight]Loading weights:   1%|          | 2/199 [00:00<00:15, 12.68it/s, Materializing param=bert.embeddings.LayerNorm.weight]Loading weights:   2%|▏         | 3/199 [00:00<00:10, 18.98it/s, Materializing param=bert.embeddings.LayerNorm.weight]Loading weights:   2%|▏         | 3/199 [00:00<00:10, 18.98it/s, Materializing param=bert.embeddings.position_embeddings.weight]Loading weights:   2%|▏         | 3/199 [00:00<00:10, 18.98it/s, Materializing param=bert.embeddings.position_embeddings.weight]Loading weights:   2%|▏         | 4/199 [00:00<00:10, 18.98it/s, Materializing param=bert.embeddings.token_type_embeddings.weight]Loading weights:   2%|▏         | 4/199 [00:00<00:10, 18.98it/s, Materializing param=bert.embeddings.token_type_embeddings.weight]Loading weights:   3%|▎         | 5/199 [00:00<00:18, 10.63it/s, Materializing param=bert.embeddings.token_type_embeddings.weight]Loading weights:   3%|▎         | 5/199 [00:00<00:18, 10.63it/s, Materializing param=bert.embeddings.word_embeddings.weight]      Loading weights:   3%|▎         | 5/199 [00:00<00:18, 10.63it/s, Materializing param=bert.embeddings.word_embeddings.weight]Loading weights:   3%|▎         | 6/199 [00:00<00:18, 10.63it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   3%|▎         | 6/199 [00:00<00:18, 10.63it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   4%|▎         | 7/199 [00:00<00:16, 11.57it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   4%|▎         | 7/199 [00:00<00:16, 11.57it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.weight]Loading weights:   4%|▎         | 7/199 [00:00<00:16, 11.57it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.weight]Loading weights:   4%|▍         | 8/199 [00:00<00:16, 11.57it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.bias]      Loading weights:   4%|▍         | 8/199 [00:00<00:16, 11.57it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.bias]Loading weights:   5%|▍         | 9/199 [00:00<00:19,  9.93it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.bias]Loading weights:   5%|▍         | 9/199 [00:00<00:19,  9.93it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.weight]Loading weights:   5%|▍         | 9/199 [00:00<00:19,  9.93it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.weight]Loading weights:   5%|▌         | 10/199 [00:00<00:19,  9.93it/s, Materializing param=bert.encoder.layer.0.attention.self.key.bias]     Loading weights:   5%|▌         | 10/199 [00:00<00:19,  9.93it/s, Materializing param=bert.encoder.layer.0.attention.self.key.bias]Loading weights:   6%|▌         | 11/199 [00:00<00:18,  9.93it/s, Materializing param=bert.encoder.layer.0.attention.self.key.weight]Loading weights:   6%|▌         | 11/199 [00:00<00:18,  9.93it/s, Materializing param=bert.encoder.layer.0.attention.self.key.weight]Loading weights:   6%|▌         | 12/199 [00:00<00:18,  9.93it/s, Materializing param=bert.encoder.layer.0.attention.self.query.bias]Loading weights:   6%|▌         | 12/199 [00:00<00:18,  9.93it/s, Materializing param=bert.encoder.layer.0.attention.self.query.bias]Loading weights:   7%|▋         | 13/199 [00:00<00:11, 15.73it/s, Materializing param=bert.encoder.layer.0.attention.self.query.bias]Loading weights:   7%|▋         | 13/199 [00:00<00:11, 15.73it/s, Materializing param=bert.encoder.layer.0.attention.self.query.weight]Loading weights:   7%|▋         | 13/199 [00:00<00:11, 15.73it/s, Materializing param=bert.encoder.layer.0.attention.self.query.weight]Loading weights:   7%|▋         | 14/199 [00:00<00:11, 15.73it/s, Materializing param=bert.encoder.layer.0.attention.self.value.bias]  Loading weights:   7%|▋         | 14/199 [00:00<00:11, 15.73it/s, Materializing param=bert.encoder.layer.0.attention.self.value.bias]Loading weights:   8%|▊         | 15/199 [00:01<00:11, 16.07it/s, Materializing param=bert.encoder.layer.0.attention.self.value.bias]Loading weights:   8%|▊         | 15/199 [00:01<00:11, 16.07it/s, Materializing param=bert.encoder.layer.0.attention.self.value.weight]Loading weights:   8%|▊         | 15/199 [00:01<00:11, 16.07it/s, Materializing param=bert.encoder.layer.0.attention.self.value.weight]Loading weights:   8%|▊         | 16/199 [00:01<00:11, 16.07it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.bias]    Loading weights:   8%|▊         | 16/199 [00:01<00:11, 16.07it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.bias]Loading weights:   9%|▊         | 17/199 [00:01<00:11, 16.07it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.weight]Loading weights:   9%|▊         | 17/199 [00:01<00:11, 16.07it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.weight]Loading weights:   9%|▉         | 18/199 [00:01<00:11, 16.07it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.bias]    Loading weights:   9%|▉         | 18/199 [00:01<00:11, 16.07it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.bias]Loading weights:  10%|▉         | 19/199 [00:01<00:08, 21.36it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.bias]Loading weights:  10%|▉         | 19/199 [00:01<00:08, 21.36it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.weight]Loading weights:  10%|▉         | 19/199 [00:01<00:08, 21.36it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.weight]Loading weights:  10%|█         | 20/199 [00:01<00:08, 21.36it/s, Materializing param=bert.encoder.layer.0.output.dense.bias]      Loading weights:  10%|█         | 20/199 [00:01<00:08, 21.36it/s, Materializing param=bert.encoder.layer.0.output.dense.bias]Loading weights:  11%|█         | 21/199 [00:01<00:08, 21.36it/s, Materializing param=bert.encoder.layer.0.output.dense.weight]Loading weights:  11%|█         | 21/199 [00:01<00:08, 21.36it/s, Materializing param=bert.encoder.layer.0.output.dense.weight]Loading weights:  11%|█         | 22/199 [00:01<00:09, 19.55it/s, Materializing param=bert.encoder.layer.0.output.dense.weight]Loading weights:  11%|█         | 22/199 [00:01<00:09, 19.55it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.bias]Loading weights:  11%|█         | 22/199 [00:01<00:09, 19.55it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.bias]Loading weights:  12%|█▏        | 23/199 [00:01<00:09, 19.55it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.weight]Loading weights:  12%|█▏        | 23/199 [00:01<00:09, 19.55it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.weight]Loading weights:  12%|█▏        | 24/199 [00:01<00:08, 19.55it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.bias]      Loading weights:  12%|█▏        | 24/199 [00:01<00:08, 19.55it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.bias]Loading weights:  13%|█▎        | 25/199 [00:01<00:12, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.bias]Loading weights:  13%|█▎        | 25/199 [00:01<00:12, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.weight]Loading weights:  13%|█▎        | 25/199 [00:01<00:12, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.weight]Loading weights:  13%|█▎        | 26/199 [00:01<00:12, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.self.key.bias]      Loading weights:  13%|█▎        | 26/199 [00:01<00:12, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.self.key.bias]Loading weights:  14%|█▎        | 27/199 [00:01<00:11, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.self.key.weight]Loading weights:  14%|█▎        | 27/199 [00:01<00:11, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.self.key.weight]Loading weights:  14%|█▍        | 28/199 [00:01<00:11, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.self.query.bias]Loading weights:  14%|█▍        | 28/199 [00:01<00:11, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.self.query.bias]Loading weights:  15%|█▍        | 29/199 [00:01<00:11, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.self.query.weight]Loading weights:  15%|█▍        | 29/199 [00:01<00:11, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.self.query.weight]Loading weights:  15%|█▌        | 30/199 [00:01<00:11, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.self.value.bias]  Loading weights:  15%|█▌        | 30/199 [00:01<00:11, 14.37it/s, Materializing param=bert.encoder.layer.1.attention.self.value.bias]Loading weights:  16%|█▌        | 31/199 [00:01<00:08, 20.47it/s, Materializing param=bert.encoder.layer.1.attention.self.value.bias]Loading weights:  16%|█▌        | 31/199 [00:01<00:08, 20.47it/s, Materializing param=bert.encoder.layer.1.attention.self.value.weight]Loading weights:  16%|█▌        | 31/199 [00:01<00:08, 20.47it/s, Materializing param=bert.encoder.layer.1.attention.self.value.weight]Loading weights:  16%|█▌        | 32/199 [00:01<00:08, 20.47it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.bias]    Loading weights:  16%|█▌        | 32/199 [00:01<00:08, 20.47it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.bias]Loading weights:  17%|█▋        | 33/199 [00:01<00:08, 20.47it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.weight]Loading weights:  17%|█▋        | 33/199 [00:01<00:08, 20.47it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.weight]Loading weights:  17%|█▋        | 34/199 [00:01<00:08, 20.47it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.bias]    Loading weights:  17%|█▋        | 34/199 [00:01<00:08, 20.47it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.bias]Loading weights:  18%|█▊        | 35/199 [00:01<00:08, 20.47it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.weight]Loading weights:  18%|█▊        | 35/199 [00:01<00:08, 20.47it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.weight]Loading weights:  18%|█▊        | 36/199 [00:01<00:07, 20.47it/s, Materializing param=bert.encoder.layer.1.output.dense.bias]      Loading weights:  18%|█▊        | 36/199 [00:01<00:07, 20.47it/s, Materializing param=bert.encoder.layer.1.output.dense.bias]Loading weights:  19%|█▊        | 37/199 [00:01<00:05, 27.56it/s, Materializing param=bert.encoder.layer.1.output.dense.bias]Loading weights:  19%|█▊        | 37/199 [00:01<00:05, 27.56it/s, Materializing param=bert.encoder.layer.1.output.dense.weight]Loading weights:  19%|█▊        | 37/199 [00:01<00:05, 27.56it/s, Materializing param=bert.encoder.layer.1.output.dense.weight]Loading weights:  19%|█▉        | 38/199 [00:01<00:05, 27.56it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.bias]Loading weights:  19%|█▉        | 38/199 [00:01<00:05, 27.56it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.bias]Loading weights:  20%|█▉        | 39/199 [00:02<00:05, 27.56it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.weight]Loading weights:  20%|█▉        | 39/199 [00:02<00:05, 27.56it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.weight]Loading weights:  20%|██        | 40/199 [00:02<00:05, 27.56it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.bias]      Loading weights:  20%|██        | 40/199 [00:02<00:05, 27.56it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.bias]Loading weights:  21%|██        | 41/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.bias]Loading weights:  21%|██        | 41/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.weight]Loading weights:  21%|██        | 41/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.weight]Loading weights:  21%|██        | 42/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.self.key.bias]      Loading weights:  21%|██        | 42/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.self.key.bias]Loading weights:  22%|██▏       | 43/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.self.key.weight]Loading weights:  22%|██▏       | 43/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.self.key.weight]Loading weights:  22%|██▏       | 44/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.self.query.bias]Loading weights:  22%|██▏       | 44/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.self.query.bias]Loading weights:  23%|██▎       | 45/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.self.query.weight]Loading weights:  23%|██▎       | 45/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.self.query.weight]Loading weights:  23%|██▎       | 46/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.self.value.bias]  Loading weights:  23%|██▎       | 46/199 [00:02<00:05, 29.79it/s, Materializing param=bert.encoder.layer.2.attention.self.value.bias]Loading weights:  24%|██▎       | 47/199 [00:02<00:04, 31.35it/s, Materializing param=bert.encoder.layer.2.attention.self.value.bias]Loading weights:  24%|██▎       | 47/199 [00:02<00:04, 31.35it/s, Materializing param=bert.encoder.layer.2.attention.self.value.weight]Loading weights:  24%|██▎       | 47/199 [00:02<00:04, 31.35it/s, Materializing param=bert.encoder.layer.2.attention.self.value.weight]Loading weights:  24%|██▍       | 48/199 [00:02<00:04, 31.35it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.bias]    Loading weights:  24%|██▍       | 48/199 [00:02<00:04, 31.35it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.bias]Loading weights:  25%|██▍       | 49/199 [00:02<00:04, 31.35it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.weight]Loading weights:  25%|██▍       | 49/199 [00:02<00:04, 31.35it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.weight]Loading weights:  25%|██▌       | 50/199 [00:02<00:04, 31.35it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.bias]    Loading weights:  25%|██▌       | 50/199 [00:02<00:04, 31.35it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.bias]Loading weights:  26%|██▌       | 51/199 [00:02<00:05, 28.72it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.bias]Loading weights:  26%|██▌       | 51/199 [00:02<00:05, 28.72it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.weight]Loading weights:  26%|██▌       | 51/199 [00:02<00:05, 28.72it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.weight]Loading weights:  26%|██▌       | 52/199 [00:02<00:05, 28.72it/s, Materializing param=bert.encoder.layer.2.output.dense.bias]      Loading weights:  26%|██▌       | 52/199 [00:02<00:05, 28.72it/s, Materializing param=bert.encoder.layer.2.output.dense.bias]Loading weights:  27%|██▋       | 53/199 [00:02<00:05, 28.72it/s, Materializing param=bert.encoder.layer.2.output.dense.weight]Loading weights:  27%|██▋       | 53/199 [00:02<00:05, 28.72it/s, Materializing param=bert.encoder.layer.2.output.dense.weight]Loading weights:  27%|██▋       | 54/199 [00:02<00:05, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.bias]Loading weights:  27%|██▋       | 54/199 [00:02<00:05, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.bias]Loading weights:  28%|██▊       | 55/199 [00:02<00:05, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.weight]Loading weights:  28%|██▊       | 55/199 [00:02<00:05, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.weight]Loading weights:  28%|██▊       | 56/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.bias]      Loading weights:  28%|██▊       | 56/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.bias]Loading weights:  29%|██▊       | 57/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.weight]Loading weights:  29%|██▊       | 57/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.weight]Loading weights:  29%|██▉       | 58/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.self.key.bias]      Loading weights:  29%|██▉       | 58/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.self.key.bias]Loading weights:  30%|██▉       | 59/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.self.key.weight]Loading weights:  30%|██▉       | 59/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.self.key.weight]Loading weights:  30%|███       | 60/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.self.query.bias]Loading weights:  30%|███       | 60/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.self.query.bias]Loading weights:  31%|███       | 61/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.self.query.weight]Loading weights:  31%|███       | 61/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.self.query.weight]Loading weights:  31%|███       | 62/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.self.value.bias]  Loading weights:  31%|███       | 62/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.self.value.bias]Loading weights:  32%|███▏      | 63/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.self.value.weight]Loading weights:  32%|███▏      | 63/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.attention.self.value.weight]Loading weights:  32%|███▏      | 64/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.bias]    Loading weights:  32%|███▏      | 64/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.bias]Loading weights:  33%|███▎      | 65/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.weight]Loading weights:  33%|███▎      | 65/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.weight]Loading weights:  33%|███▎      | 66/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.bias]    Loading weights:  33%|███▎      | 66/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.bias]Loading weights:  34%|███▎      | 67/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.weight]Loading weights:  34%|███▎      | 67/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.weight]Loading weights:  34%|███▍      | 68/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.output.dense.bias]      Loading weights:  34%|███▍      | 68/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.output.dense.bias]Loading weights:  35%|███▍      | 69/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.output.dense.weight]Loading weights:  35%|███▍      | 69/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.3.output.dense.weight]Loading weights:  35%|███▌      | 70/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.bias]Loading weights:  35%|███▌      | 70/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.bias]Loading weights:  36%|███▌      | 71/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.weight]Loading weights:  36%|███▌      | 71/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.weight]Loading weights:  36%|███▌      | 72/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.bias]      Loading weights:  36%|███▌      | 72/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.bias]Loading weights:  37%|███▋      | 73/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.weight]Loading weights:  37%|███▋      | 73/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.weight]Loading weights:  37%|███▋      | 74/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.self.key.bias]      Loading weights:  37%|███▋      | 74/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.self.key.bias]Loading weights:  38%|███▊      | 75/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.self.key.weight]Loading weights:  38%|███▊      | 75/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.self.key.weight]Loading weights:  38%|███▊      | 76/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.self.query.bias]Loading weights:  38%|███▊      | 76/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.self.query.bias]Loading weights:  39%|███▊      | 77/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.self.query.weight]Loading weights:  39%|███▊      | 77/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.self.query.weight]Loading weights:  39%|███▉      | 78/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.self.value.bias]  Loading weights:  39%|███▉      | 78/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.self.value.bias]Loading weights:  40%|███▉      | 79/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.self.value.weight]Loading weights:  40%|███▉      | 79/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.attention.self.value.weight]Loading weights:  40%|████      | 80/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.bias]    Loading weights:  40%|████      | 80/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.bias]Loading weights:  41%|████      | 81/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.weight]Loading weights:  41%|████      | 81/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.weight]Loading weights:  41%|████      | 82/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.bias]    Loading weights:  41%|████      | 82/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.bias]Loading weights:  42%|████▏     | 83/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.weight]Loading weights:  42%|████▏     | 83/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.weight]Loading weights:  42%|████▏     | 84/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.output.dense.bias]      Loading weights:  42%|████▏     | 84/199 [00:02<00:04, 28.72it/s, Materializing param=bert.encoder.layer.4.output.dense.bias]Loading weights:  43%|████▎     | 85/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.4.output.dense.weight]Loading weights:  43%|████▎     | 85/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.4.output.dense.weight]Loading weights:  43%|████▎     | 86/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.bias]Loading weights:  43%|████▎     | 86/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.bias]Loading weights:  44%|████▎     | 87/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.weight]Loading weights:  44%|████▎     | 87/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.weight]Loading weights:  44%|████▍     | 88/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.bias]      Loading weights:  44%|████▍     | 88/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.bias]Loading weights:  45%|████▍     | 89/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.weight]Loading weights:  45%|████▍     | 89/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.weight]Loading weights:  45%|████▌     | 90/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.self.key.bias]      Loading weights:  45%|████▌     | 90/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.self.key.bias]Loading weights:  46%|████▌     | 91/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.self.key.weight]Loading weights:  46%|████▌     | 91/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.self.key.weight]Loading weights:  46%|████▌     | 92/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.self.query.bias]Loading weights:  46%|████▌     | 92/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.self.query.bias]Loading weights:  47%|████▋     | 93/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.self.query.weight]Loading weights:  47%|████▋     | 93/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.self.query.weight]Loading weights:  47%|████▋     | 94/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.self.value.bias]  Loading weights:  47%|████▋     | 94/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.self.value.bias]Loading weights:  48%|████▊     | 95/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.self.value.weight]Loading weights:  48%|████▊     | 95/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.attention.self.value.weight]Loading weights:  48%|████▊     | 96/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.bias]    Loading weights:  48%|████▊     | 96/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.bias]Loading weights:  49%|████▊     | 97/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.weight]Loading weights:  49%|████▊     | 97/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.weight]Loading weights:  49%|████▉     | 98/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.bias]    Loading weights:  49%|████▉     | 98/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.bias]Loading weights:  50%|████▉     | 99/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.weight]Loading weights:  50%|████▉     | 99/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.weight]Loading weights:  50%|█████     | 100/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.output.dense.bias]     Loading weights:  50%|█████     | 100/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.output.dense.bias]Loading weights:  51%|█████     | 101/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.output.dense.weight]Loading weights:  51%|█████     | 101/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.5.output.dense.weight]Loading weights:  51%|█████▏    | 102/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.output.LayerNorm.bias]Loading weights:  51%|█████▏    | 102/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.output.LayerNorm.bias]Loading weights:  52%|█████▏    | 103/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.output.LayerNorm.weight]Loading weights:  52%|█████▏    | 103/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.output.LayerNorm.weight]Loading weights:  52%|█████▏    | 104/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.output.dense.bias]      Loading weights:  52%|█████▏    | 104/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.output.dense.bias]Loading weights:  53%|█████▎    | 105/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.output.dense.weight]Loading weights:  53%|█████▎    | 105/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.output.dense.weight]Loading weights:  53%|█████▎    | 106/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.self.key.bias]      Loading weights:  53%|█████▎    | 106/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.self.key.bias]Loading weights:  54%|█████▍    | 107/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.self.key.weight]Loading weights:  54%|█████▍    | 107/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.self.key.weight]Loading weights:  54%|█████▍    | 108/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.self.query.bias]Loading weights:  54%|█████▍    | 108/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.self.query.bias]Loading weights:  55%|█████▍    | 109/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.self.query.weight]Loading weights:  55%|█████▍    | 109/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.self.query.weight]Loading weights:  55%|█████▌    | 110/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.self.value.bias]  Loading weights:  55%|█████▌    | 110/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.self.value.bias]Loading weights:  56%|█████▌    | 111/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.self.value.weight]Loading weights:  56%|█████▌    | 111/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.attention.self.value.weight]Loading weights:  56%|█████▋    | 112/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.intermediate.dense.bias]    Loading weights:  56%|█████▋    | 112/199 [00:02<00:03, 28.72it/s, Materializing param=bert.encoder.layer.6.intermediate.dense.bias]Loading weights:  57%|█████▋    | 113/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.6.intermediate.dense.weight]Loading weights:  57%|█████▋    | 113/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.6.intermediate.dense.weight]Loading weights:  57%|█████▋    | 114/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.6.output.LayerNorm.bias]    Loading weights:  57%|█████▋    | 114/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.6.output.LayerNorm.bias]Loading weights:  58%|█████▊    | 115/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.6.output.LayerNorm.weight]Loading weights:  58%|█████▊    | 115/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.6.output.LayerNorm.weight]Loading weights:  58%|█████▊    | 116/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.6.output.dense.bias]      Loading weights:  58%|█████▊    | 116/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.6.output.dense.bias]Loading weights:  59%|█████▉    | 117/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.6.output.dense.weight]Loading weights:  59%|█████▉    | 117/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.6.output.dense.weight]Loading weights:  59%|█████▉    | 118/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.output.LayerNorm.bias]Loading weights:  59%|█████▉    | 118/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.output.LayerNorm.bias]Loading weights:  60%|█████▉    | 119/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.output.LayerNorm.weight]Loading weights:  60%|█████▉    | 119/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.output.LayerNorm.weight]Loading weights:  60%|██████    | 120/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.output.dense.bias]      Loading weights:  60%|██████    | 120/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.output.dense.bias]Loading weights:  61%|██████    | 121/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.output.dense.weight]Loading weights:  61%|██████    | 121/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.output.dense.weight]Loading weights:  61%|██████▏   | 122/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.self.key.bias]      Loading weights:  61%|██████▏   | 122/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.self.key.bias]Loading weights:  62%|██████▏   | 123/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.self.key.weight]Loading weights:  62%|██████▏   | 123/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.self.key.weight]Loading weights:  62%|██████▏   | 124/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.self.query.bias]Loading weights:  62%|██████▏   | 124/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.self.query.bias]Loading weights:  63%|██████▎   | 125/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.self.query.weight]Loading weights:  63%|██████▎   | 125/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.self.query.weight]Loading weights:  63%|██████▎   | 126/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.self.value.bias]  Loading weights:  63%|██████▎   | 126/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.self.value.bias]Loading weights:  64%|██████▍   | 127/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.self.value.weight]Loading weights:  64%|██████▍   | 127/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.attention.self.value.weight]Loading weights:  64%|██████▍   | 128/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.intermediate.dense.bias]    Loading weights:  64%|██████▍   | 128/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.intermediate.dense.bias]Loading weights:  65%|██████▍   | 129/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.intermediate.dense.weight]Loading weights:  65%|██████▍   | 129/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.intermediate.dense.weight]Loading weights:  65%|██████▌   | 130/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.output.LayerNorm.bias]    Loading weights:  65%|██████▌   | 130/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.output.LayerNorm.bias]Loading weights:  66%|██████▌   | 131/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.output.LayerNorm.weight]Loading weights:  66%|██████▌   | 131/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.output.LayerNorm.weight]Loading weights:  66%|██████▋   | 132/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.output.dense.bias]      Loading weights:  66%|██████▋   | 132/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.output.dense.bias]Loading weights:  67%|██████▋   | 133/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.output.dense.weight]Loading weights:  67%|██████▋   | 133/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.7.output.dense.weight]Loading weights:  67%|██████▋   | 134/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.output.LayerNorm.bias]Loading weights:  67%|██████▋   | 134/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.output.LayerNorm.bias]Loading weights:  68%|██████▊   | 135/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.output.LayerNorm.weight]Loading weights:  68%|██████▊   | 135/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.output.LayerNorm.weight]Loading weights:  68%|██████▊   | 136/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.output.dense.bias]      Loading weights:  68%|██████▊   | 136/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.output.dense.bias]Loading weights:  69%|██████▉   | 137/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.output.dense.weight]Loading weights:  69%|██████▉   | 137/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.output.dense.weight]Loading weights:  69%|██████▉   | 138/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.self.key.bias]      Loading weights:  69%|██████▉   | 138/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.self.key.bias]Loading weights:  70%|██████▉   | 139/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.self.key.weight]Loading weights:  70%|██████▉   | 139/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.self.key.weight]Loading weights:  70%|███████   | 140/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.self.query.bias]Loading weights:  70%|███████   | 140/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.self.query.bias]Loading weights:  71%|███████   | 141/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.self.query.weight]Loading weights:  71%|███████   | 141/199 [00:02<00:02, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.self.query.weight]Loading weights:  71%|███████▏  | 142/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.self.value.bias]  Loading weights:  71%|███████▏  | 142/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.self.value.bias]Loading weights:  72%|███████▏  | 143/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.self.value.weight]Loading weights:  72%|███████▏  | 143/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.attention.self.value.weight]Loading weights:  72%|███████▏  | 144/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.intermediate.dense.bias]    Loading weights:  72%|███████▏  | 144/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.intermediate.dense.bias]Loading weights:  73%|███████▎  | 145/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.intermediate.dense.weight]Loading weights:  73%|███████▎  | 145/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.intermediate.dense.weight]Loading weights:  73%|███████▎  | 146/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.output.LayerNorm.bias]    Loading weights:  73%|███████▎  | 146/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.output.LayerNorm.bias]Loading weights:  74%|███████▍  | 147/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.output.LayerNorm.weight]Loading weights:  74%|███████▍  | 147/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.output.LayerNorm.weight]Loading weights:  74%|███████▍  | 148/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.output.dense.bias]      Loading weights:  74%|███████▍  | 148/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.output.dense.bias]Loading weights:  75%|███████▍  | 149/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.output.dense.weight]Loading weights:  75%|███████▍  | 149/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.8.output.dense.weight]Loading weights:  75%|███████▌  | 150/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.output.LayerNorm.bias]Loading weights:  75%|███████▌  | 150/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.output.LayerNorm.bias]Loading weights:  76%|███████▌  | 151/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.output.LayerNorm.weight]Loading weights:  76%|███████▌  | 151/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.output.LayerNorm.weight]Loading weights:  76%|███████▋  | 152/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.output.dense.bias]      Loading weights:  76%|███████▋  | 152/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.output.dense.bias]Loading weights:  77%|███████▋  | 153/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.output.dense.weight]Loading weights:  77%|███████▋  | 153/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.output.dense.weight]Loading weights:  77%|███████▋  | 154/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.self.key.bias]      Loading weights:  77%|███████▋  | 154/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.self.key.bias]Loading weights:  78%|███████▊  | 155/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.self.key.weight]Loading weights:  78%|███████▊  | 155/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.self.key.weight]Loading weights:  78%|███████▊  | 156/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.self.query.bias]Loading weights:  78%|███████▊  | 156/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.self.query.bias]Loading weights:  79%|███████▉  | 157/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.self.query.weight]Loading weights:  79%|███████▉  | 157/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.self.query.weight]Loading weights:  79%|███████▉  | 158/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.self.value.bias]  Loading weights:  79%|███████▉  | 158/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.self.value.bias]Loading weights:  80%|███████▉  | 159/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.self.value.weight]Loading weights:  80%|███████▉  | 159/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.attention.self.value.weight]Loading weights:  80%|████████  | 160/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.intermediate.dense.bias]    Loading weights:  80%|████████  | 160/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.intermediate.dense.bias]Loading weights:  81%|████████  | 161/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.intermediate.dense.weight]Loading weights:  81%|████████  | 161/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.intermediate.dense.weight]Loading weights:  81%|████████▏ | 162/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.output.LayerNorm.bias]    Loading weights:  81%|████████▏ | 162/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.output.LayerNorm.bias]Loading weights:  82%|████████▏ | 163/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.output.LayerNorm.weight]Loading weights:  82%|████████▏ | 163/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.output.LayerNorm.weight]Loading weights:  82%|████████▏ | 164/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.output.dense.bias]      Loading weights:  82%|████████▏ | 164/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.output.dense.bias]Loading weights:  83%|████████▎ | 165/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.output.dense.weight]Loading weights:  83%|████████▎ | 165/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.9.output.dense.weight]Loading weights:  83%|████████▎ | 166/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.output.LayerNorm.bias]Loading weights:  83%|████████▎ | 166/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.output.LayerNorm.bias]Loading weights:  84%|████████▍ | 167/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.output.LayerNorm.weight]Loading weights:  84%|████████▍ | 167/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.output.LayerNorm.weight]Loading weights:  84%|████████▍ | 168/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.output.dense.bias]      Loading weights:  84%|████████▍ | 168/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.output.dense.bias]Loading weights:  85%|████████▍ | 169/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.output.dense.weight]Loading weights:  85%|████████▍ | 169/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.output.dense.weight]Loading weights:  85%|████████▌ | 170/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.self.key.bias]      Loading weights:  85%|████████▌ | 170/199 [00:02<00:01, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.self.key.bias]Loading weights:  86%|████████▌ | 171/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.self.key.weight]Loading weights:  86%|████████▌ | 171/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.self.key.weight]Loading weights:  86%|████████▋ | 172/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.self.query.bias]Loading weights:  86%|████████▋ | 172/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.self.query.bias]Loading weights:  87%|████████▋ | 173/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.self.query.weight]Loading weights:  87%|████████▋ | 173/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.self.query.weight]Loading weights:  87%|████████▋ | 174/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.self.value.bias]  Loading weights:  87%|████████▋ | 174/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.self.value.bias]Loading weights:  88%|████████▊ | 175/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.self.value.weight]Loading weights:  88%|████████▊ | 175/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.attention.self.value.weight]Loading weights:  88%|████████▊ | 176/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.intermediate.dense.bias]    Loading weights:  88%|████████▊ | 176/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.intermediate.dense.bias]Loading weights:  89%|████████▉ | 177/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.intermediate.dense.weight]Loading weights:  89%|████████▉ | 177/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.intermediate.dense.weight]Loading weights:  89%|████████▉ | 178/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.output.LayerNorm.bias]    Loading weights:  89%|████████▉ | 178/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.output.LayerNorm.bias]Loading weights:  90%|████████▉ | 179/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.output.LayerNorm.weight]Loading weights:  90%|████████▉ | 179/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.output.LayerNorm.weight]Loading weights:  90%|█████████ | 180/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.output.dense.bias]      Loading weights:  90%|█████████ | 180/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.output.dense.bias]Loading weights:  91%|█████████ | 181/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.output.dense.weight]Loading weights:  91%|█████████ | 181/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.10.output.dense.weight]Loading weights:  91%|█████████▏| 182/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.output.LayerNorm.bias]Loading weights:  91%|█████████▏| 182/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.output.LayerNorm.bias]Loading weights:  92%|█████████▏| 183/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.output.LayerNorm.weight]Loading weights:  92%|█████████▏| 183/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.output.LayerNorm.weight]Loading weights:  92%|█████████▏| 184/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.output.dense.bias]      Loading weights:  92%|█████████▏| 184/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.output.dense.bias]Loading weights:  93%|█████████▎| 185/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.output.dense.weight]Loading weights:  93%|█████████▎| 185/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.output.dense.weight]Loading weights:  93%|█████████▎| 186/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.self.key.bias]      Loading weights:  93%|█████████▎| 186/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.self.key.bias]Loading weights:  94%|█████████▍| 187/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.self.key.weight]Loading weights:  94%|█████████▍| 187/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.self.key.weight]Loading weights:  94%|█████████▍| 188/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.self.query.bias]Loading weights:  94%|█████████▍| 188/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.self.query.bias]Loading weights:  95%|█████████▍| 189/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.self.query.weight]Loading weights:  95%|█████████▍| 189/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.self.query.weight]Loading weights:  95%|█████████▌| 190/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.self.value.bias]  Loading weights:  95%|█████████▌| 190/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.self.value.bias]Loading weights:  96%|█████████▌| 191/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.self.value.weight]Loading weights:  96%|█████████▌| 191/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.attention.self.value.weight]Loading weights:  96%|█████████▋| 192/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.intermediate.dense.bias]    Loading weights:  96%|█████████▋| 192/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.intermediate.dense.bias]Loading weights:  97%|█████████▋| 193/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.intermediate.dense.weight]Loading weights:  97%|█████████▋| 193/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.intermediate.dense.weight]Loading weights:  97%|█████████▋| 194/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.output.LayerNorm.bias]    Loading weights:  97%|█████████▋| 194/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.output.LayerNorm.bias]Loading weights:  98%|█████████▊| 195/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.output.LayerNorm.weight]Loading weights:  98%|█████████▊| 195/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.output.LayerNorm.weight]Loading weights:  98%|█████████▊| 196/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.output.dense.bias]      Loading weights:  98%|█████████▊| 196/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.output.dense.bias]Loading weights:  99%|█████████▉| 197/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.output.dense.weight]Loading weights:  99%|█████████▉| 197/199 [00:02<00:00, 28.72it/s, Materializing param=bert.encoder.layer.11.output.dense.weight]Loading weights:  99%|█████████▉| 198/199 [00:02<00:00, 28.72it/s, Materializing param=bert.pooler.dense.bias]                   Loading weights:  99%|█████████▉| 198/199 [00:02<00:00, 28.72it/s, Materializing param=bert.pooler.dense.bias]Loading weights: 100%|██████████| 199/199 [00:02<00:00, 28.72it/s, Materializing param=bert.pooler.dense.weight]Loading weights: 100%|██████████| 199/199 [00:02<00:00, 28.72it/s, Materializing param=bert.pooler.dense.weight]Loading weights: 100%|██████████| 199/199 [00:02<00:00, 82.11it/s, Materializing param=bert.pooler.dense.weight]
BertForSequenceClassification LOAD REPORT from: bert-base-uncased
Key                                        | Status     | 
-------------------------------------------+------------+-
cls.predictions.transform.LayerNorm.weight | UNEXPECTED | 
cls.predictions.bias                       | UNEXPECTED | 
cls.seq_relationship.weight                | UNEXPECTED | 
cls.seq_relationship.bias                  | UNEXPECTED | 
cls.predictions.transform.dense.bias       | UNEXPECTED | 
cls.predictions.transform.dense.weight     | UNEXPECTED | 
cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | 
classifier.weight                          | MISSING    | 
classifier.bias                            | MISSING    | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
- MISSING	:those params were newly initialized because missing form the checkpoint. Consider training on your downstream task.
/home/zhisheng/stats507/train/run_finetune.py:158: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=args.use_amp)
2025-12-02 13:38:39 - INFO - train - Epoch 1/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 13:50:43 - INFO - train - Train metrics: {
  "accuracy": 0.7058823529411765,
  "auroc": 0.717426680225506,
  "macro_f1": 0.6472258739186268,
  "loss": 0.5763125897295335
}
2025-12-02 13:51:59 - INFO - train - Val metrics: {
  "accuracy": 0.5951923076923077,
  "auroc": 0.6194585601593535,
  "macro_f1": 0.5501762453524343,
  "loss": 0.7300096603540274
}
2025-12-02 13:52:05 - INFO - train - Saved new best checkpoint with AUROC=0.6195
2025-12-02 13:52:05 - INFO - train - Epoch 2/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 14:05:11 - INFO - train - Train metrics: {
  "accuracy": 0.7787058823529411,
  "auroc": 0.8287739650945098,
  "macro_f1": 0.7479547541540883,
  "loss": 0.4798242134206435
}
2025-12-02 14:06:30 - INFO - train - Val metrics: {
  "accuracy": 0.5855769230769231,
  "auroc": 0.6247967525681799,
  "macro_f1": 0.43338149540058585,
  "loss": 0.8938982587594252
}
2025-12-02 14:06:35 - INFO - train - Saved new best checkpoint with AUROC=0.6248
2025-12-02 14:06:35 - INFO - train - Epoch 3/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 14:21:40 - INFO - train - Train metrics: {
  "accuracy": 0.82,
  "auroc": 0.896605026403658,
  "macro_f1": 0.8005560322989729,
  "loss": 0.3843191855654997
}
2025-12-02 14:23:07 - INFO - train - Val metrics: {
  "accuracy": 0.5913461538461539,
  "auroc": 0.605879179540576,
  "macro_f1": 0.5332190670506521,
  "loss": 0.8750603199005127
}
2025-12-02 14:23:07 - INFO - train - Epoch 4/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 14:35:18 - INFO - train - Train metrics: {
  "accuracy": 0.8503529411764705,
  "auroc": 0.9368105567977643,
  "macro_f1": 0.8365510641868144,
  "loss": 0.30084979368658626
}
2025-12-02 14:36:34 - INFO - train - Val metrics: {
  "accuracy": 0.5826923076923077,
  "auroc": 0.5824646981374801,
  "macro_f1": 0.5191729980100477,
  "loss": 1.0808458520815922
}
2025-12-02 14:36:34 - INFO - train - Epoch 5/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 14:49:24 - INFO - train - Train metrics: {
  "accuracy": 0.8681176470588235,
  "auroc": 0.9537621579174502,
  "macro_f1": 0.8579797798441404,
  "loss": 0.2515476843469283
}
2025-12-02 14:50:37 - INFO - train - Val metrics: {
  "accuracy": 0.5875,
  "auroc": 0.5716638183731906,
  "macro_f1": 0.5446598880020085,
  "loss": 1.186719440955382
}
2025-12-02 14:50:37 - INFO - train - Epoch 6/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 15:02:06 - INFO - train - Train metrics: {
  "accuracy": 0.8788235294117647,
  "auroc": 0.9630664551739124,
  "macro_f1": 0.8696755580833486,
  "loss": 0.22130398632147733
}
2025-12-02 15:03:19 - INFO - train - Val metrics: {
  "accuracy": 0.5875,
  "auroc": 0.5664218266049473,
  "macro_f1": 0.5010015534983912,
  "loss": 1.610120782485375
}
2025-12-02 15:03:19 - INFO - train - Epoch 7/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 15:14:54 - INFO - train - Train metrics: {
  "accuracy": 0.8849411764705882,
  "auroc": 0.9677345733301691,
  "macro_f1": 0.8767602762775761,
  "loss": 0.19994959260435666
}
2025-12-02 15:16:09 - INFO - train - Val metrics: {
  "accuracy": 0.5855769230769231,
  "auroc": 0.5651089708040486,
  "macro_f1": 0.5443006574619954,
  "loss": 1.5275606531363266
}
2025-12-02 15:16:09 - INFO - train - Epoch 8/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 15:27:44 - INFO - train - Train metrics: {
  "accuracy": 0.892,
  "auroc": 0.9723968294458638,
  "macro_f1": 0.8842607631260575,
  "loss": 0.17676215365704367
}
2025-12-02 15:28:58 - INFO - train - Val metrics: {
  "accuracy": 0.5798076923076924,
  "auroc": 0.547662701691245,
  "macro_f1": 0.5271699381288422,
  "loss": 2.0054800473726715
}
2025-12-02 15:28:58 - INFO - train - Epoch 9/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 15:40:42 - INFO - train - Train metrics: {
  "accuracy": 0.8984705882352941,
  "auroc": 0.9754410414996815,
  "macro_f1": 0.8912445913810001,
  "loss": 0.16403539254034266
}
2025-12-02 15:41:58 - INFO - train - Val metrics: {
  "accuracy": 0.5846153846153846,
  "auroc": 0.5605875406966436,
  "macro_f1": 0.5393530765161115,
  "loss": 2.096857414795802
}
2025-12-02 15:41:58 - INFO - train - Epoch 10/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 15:53:56 - INFO - train - Train metrics: {
  "accuracy": 0.9050588235294118,
  "auroc": 0.978177164040261,
  "macro_f1": 0.8985758163848341,
  "loss": 0.1524047112605151
}
2025-12-02 15:55:15 - INFO - train - Val metrics: {
  "accuracy": 0.5817307692307693,
  "auroc": 0.5569771872441723,
  "macro_f1": 0.5153073523503415,
  "loss": 2.2882331187908465
}
2025-12-02 15:55:15 - INFO - train - Evaluating best checkpoint on test split.
2025-12-02 15:59:23 - INFO - train - Test metrics: {
  "accuracy": 0.6083333333333333,
  "auroc": 0.6509228372434018,
  "macro_f1": 0.458255638482999,
  "loss": 0.8434450428287188
}
2025-12-02 15:59:23 - INFO - train - Saved test predictions to logs/predictions/bert_v2/test_predictions.csv
2025-12-02 15:59:36 - INFO - train - Using device cuda
Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Loading weights:   0%|          | 0/200 [00:00<?, ?it/s]Loading weights:   0%|          | 1/200 [00:00<00:00, 15477.14it/s, Materializing param=classifier.bias]Loading weights:   0%|          | 1/200 [00:00<00:00, 6875.91it/s, Materializing param=classifier.bias] Loading weights:   1%|          | 2/200 [00:00<00:00, 6497.76it/s, Materializing param=classifier.weight]Loading weights:   1%|          | 2/200 [00:00<00:00, 4987.28it/s, Materializing param=classifier.weight]Loading weights:   2%|▏         | 3/200 [00:00<00:00, 5670.53it/s, Materializing param=vit.embeddings.cls_token]Loading weights:   2%|▏         | 3/200 [00:00<00:00, 5003.15it/s, Materializing param=vit.embeddings.cls_token]Loading weights:   2%|▏         | 4/200 [00:00<00:00, 5464.89it/s, Materializing param=vit.embeddings.patch_embeddings.projection.bias]Loading weights:   2%|▏         | 4/200 [00:00<00:00, 4993.22it/s, Materializing param=vit.embeddings.patch_embeddings.projection.bias]Loading weights:   2%|▎         | 5/200 [00:00<00:01, 143.05it/s, Materializing param=vit.embeddings.patch_embeddings.projection.weight]Loading weights:   2%|▎         | 5/200 [00:00<00:01, 142.40it/s, Materializing param=vit.embeddings.patch_embeddings.projection.weight]Loading weights:   3%|▎         | 6/200 [00:00<00:01, 169.62it/s, Materializing param=vit.embeddings.position_embeddings]               Loading weights:   3%|▎         | 6/200 [00:00<00:01, 169.29it/s, Materializing param=vit.embeddings.position_embeddings]Loading weights:   4%|▎         | 7/200 [00:00<00:00, 195.89it/s, Materializing param=vit.encoder.layer.0.attention.attention.key.bias]Loading weights:   4%|▎         | 7/200 [00:00<00:03, 54.88it/s, Materializing param=vit.encoder.layer.0.attention.attention.key.bias] Loading weights:   4%|▍         | 8/200 [00:00<00:03, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.attention.key.bias]Loading weights:   4%|▍         | 8/200 [00:00<00:03, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.attention.key.weight]Loading weights:   4%|▍         | 8/200 [00:00<00:03, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.attention.key.weight]Loading weights:   4%|▍         | 9/200 [00:00<00:03, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.attention.query.bias]Loading weights:   4%|▍         | 9/200 [00:00<00:03, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.attention.query.bias]Loading weights:   5%|▌         | 10/200 [00:00<00:03, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.attention.query.weight]Loading weights:   5%|▌         | 10/200 [00:00<00:03, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.attention.query.weight]Loading weights:   6%|▌         | 11/200 [00:00<00:03, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.attention.value.bias]  Loading weights:   6%|▌         | 11/200 [00:00<00:03, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.attention.value.bias]Loading weights:   6%|▌         | 12/200 [00:00<00:03, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.attention.value.weight]Loading weights:   6%|▌         | 12/200 [00:00<00:03, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.attention.value.weight]Loading weights:   6%|▋         | 13/200 [00:00<00:02, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.output.dense.bias]     Loading weights:   6%|▋         | 13/200 [00:00<00:02, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.output.dense.bias]Loading weights:   7%|▋         | 14/200 [00:00<00:02, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.output.dense.weight]Loading weights:   7%|▋         | 14/200 [00:00<00:02, 62.56it/s, Materializing param=vit.encoder.layer.0.attention.output.dense.weight]Loading weights:   8%|▊         | 15/200 [00:00<00:06, 29.32it/s, Materializing param=vit.encoder.layer.0.attention.output.dense.weight]Loading weights:   8%|▊         | 15/200 [00:00<00:06, 29.32it/s, Materializing param=vit.encoder.layer.0.intermediate.dense.bias]      Loading weights:   8%|▊         | 15/200 [00:00<00:06, 29.32it/s, Materializing param=vit.encoder.layer.0.intermediate.dense.bias]Loading weights:   8%|▊         | 16/200 [00:00<00:06, 29.32it/s, Materializing param=vit.encoder.layer.0.intermediate.dense.weight]Loading weights:   8%|▊         | 16/200 [00:00<00:06, 29.32it/s, Materializing param=vit.encoder.layer.0.intermediate.dense.weight]Loading weights:   8%|▊         | 17/200 [00:00<00:06, 29.32it/s, Materializing param=vit.encoder.layer.0.layernorm_after.bias]     Loading weights:   8%|▊         | 17/200 [00:01<00:06, 29.32it/s, Materializing param=vit.encoder.layer.0.layernorm_after.bias]Loading weights:   9%|▉         | 18/200 [00:01<00:06, 29.32it/s, Materializing param=vit.encoder.layer.0.layernorm_after.weight]Loading weights:   9%|▉         | 18/200 [00:01<00:06, 29.32it/s, Materializing param=vit.encoder.layer.0.layernorm_after.weight]Loading weights:  10%|▉         | 19/200 [00:01<00:13, 13.34it/s, Materializing param=vit.encoder.layer.0.layernorm_after.weight]Loading weights:  10%|▉         | 19/200 [00:01<00:13, 13.34it/s, Materializing param=vit.encoder.layer.0.layernorm_before.bias] Loading weights:  10%|▉         | 19/200 [00:01<00:13, 13.34it/s, Materializing param=vit.encoder.layer.0.layernorm_before.bias]Loading weights:  10%|█         | 20/200 [00:01<00:13, 13.34it/s, Materializing param=vit.encoder.layer.0.layernorm_before.weight]Loading weights:  10%|█         | 20/200 [00:01<00:13, 13.34it/s, Materializing param=vit.encoder.layer.0.layernorm_before.weight]Loading weights:  10%|█         | 21/200 [00:01<00:13, 13.34it/s, Materializing param=vit.encoder.layer.0.output.dense.bias]      Loading weights:  10%|█         | 21/200 [00:01<00:13, 13.34it/s, Materializing param=vit.encoder.layer.0.output.dense.bias]Loading weights:  11%|█         | 22/200 [00:01<00:14, 12.62it/s, Materializing param=vit.encoder.layer.0.output.dense.bias]Loading weights:  11%|█         | 22/200 [00:01<00:14, 12.62it/s, Materializing param=vit.encoder.layer.0.output.dense.weight]Loading weights:  11%|█         | 22/200 [00:01<00:14, 12.62it/s, Materializing param=vit.encoder.layer.0.output.dense.weight]Loading weights:  12%|█▏        | 23/200 [00:01<00:14, 12.62it/s, Materializing param=vit.encoder.layer.1.attention.attention.key.bias]Loading weights:  12%|█▏        | 23/200 [00:01<00:14, 12.62it/s, Materializing param=vit.encoder.layer.1.attention.attention.key.bias]Loading weights:  12%|█▏        | 24/200 [00:01<00:13, 13.42it/s, Materializing param=vit.encoder.layer.1.attention.attention.key.bias]Loading weights:  12%|█▏        | 24/200 [00:01<00:13, 13.42it/s, Materializing param=vit.encoder.layer.1.attention.attention.key.weight]Loading weights:  12%|█▏        | 24/200 [00:01<00:13, 13.42it/s, Materializing param=vit.encoder.layer.1.attention.attention.key.weight]Loading weights:  12%|█▎        | 25/200 [00:01<00:13, 13.42it/s, Materializing param=vit.encoder.layer.1.attention.attention.query.bias]Loading weights:  12%|█▎        | 25/200 [00:01<00:13, 13.42it/s, Materializing param=vit.encoder.layer.1.attention.attention.query.bias]Loading weights:  13%|█▎        | 26/200 [00:01<00:12, 14.24it/s, Materializing param=vit.encoder.layer.1.attention.attention.query.bias]Loading weights:  13%|█▎        | 26/200 [00:01<00:12, 14.24it/s, Materializing param=vit.encoder.layer.1.attention.attention.query.weight]Loading weights:  13%|█▎        | 26/200 [00:01<00:12, 14.24it/s, Materializing param=vit.encoder.layer.1.attention.attention.query.weight]Loading weights:  14%|█▎        | 27/200 [00:01<00:12, 14.24it/s, Materializing param=vit.encoder.layer.1.attention.attention.value.bias]  Loading weights:  14%|█▎        | 27/200 [00:01<00:12, 14.24it/s, Materializing param=vit.encoder.layer.1.attention.attention.value.bias]Loading weights:  14%|█▍        | 28/200 [00:01<00:11, 15.08it/s, Materializing param=vit.encoder.layer.1.attention.attention.value.bias]Loading weights:  14%|█▍        | 28/200 [00:01<00:11, 15.08it/s, Materializing param=vit.encoder.layer.1.attention.attention.value.weight]Loading weights:  14%|█▍        | 28/200 [00:01<00:11, 15.08it/s, Materializing param=vit.encoder.layer.1.attention.attention.value.weight]Loading weights:  14%|█▍        | 29/200 [00:01<00:11, 15.08it/s, Materializing param=vit.encoder.layer.1.attention.output.dense.bias]     Loading weights:  14%|█▍        | 29/200 [00:01<00:11, 15.08it/s, Materializing param=vit.encoder.layer.1.attention.output.dense.bias]Loading weights:  15%|█▌        | 30/200 [00:01<00:11, 15.08it/s, Materializing param=vit.encoder.layer.1.attention.output.dense.weight]Loading weights:  15%|█▌        | 30/200 [00:01<00:11, 15.08it/s, Materializing param=vit.encoder.layer.1.attention.output.dense.weight]Loading weights:  16%|█▌        | 31/200 [00:01<00:11, 15.08it/s, Materializing param=vit.encoder.layer.1.intermediate.dense.bias]      Loading weights:  16%|█▌        | 31/200 [00:01<00:11, 15.08it/s, Materializing param=vit.encoder.layer.1.intermediate.dense.bias]Loading weights:  16%|█▌        | 32/200 [00:01<00:10, 16.72it/s, Materializing param=vit.encoder.layer.1.intermediate.dense.bias]Loading weights:  16%|█▌        | 32/200 [00:01<00:10, 16.72it/s, Materializing param=vit.encoder.layer.1.intermediate.dense.weight]Loading weights:  16%|█▌        | 32/200 [00:01<00:10, 16.72it/s, Materializing param=vit.encoder.layer.1.intermediate.dense.weight]Loading weights:  16%|█▋        | 33/200 [00:01<00:09, 16.72it/s, Materializing param=vit.encoder.layer.1.layernorm_after.bias]     Loading weights:  16%|█▋        | 33/200 [00:01<00:09, 16.72it/s, Materializing param=vit.encoder.layer.1.layernorm_after.bias]Loading weights:  17%|█▋        | 34/200 [00:01<00:09, 16.72it/s, Materializing param=vit.encoder.layer.1.layernorm_after.weight]Loading weights:  17%|█▋        | 34/200 [00:01<00:09, 16.72it/s, Materializing param=vit.encoder.layer.1.layernorm_after.weight]Loading weights:  18%|█▊        | 35/200 [00:01<00:09, 16.72it/s, Materializing param=vit.encoder.layer.1.layernorm_before.bias] Loading weights:  18%|█▊        | 35/200 [00:01<00:09, 16.72it/s, Materializing param=vit.encoder.layer.1.layernorm_before.bias]Loading weights:  18%|█▊        | 36/200 [00:01<00:09, 16.72it/s, Materializing param=vit.encoder.layer.1.layernorm_before.weight]Loading weights:  18%|█▊        | 36/200 [00:01<00:09, 16.72it/s, Materializing param=vit.encoder.layer.1.layernorm_before.weight]Loading weights:  18%|█▊        | 37/200 [00:01<00:09, 16.72it/s, Materializing param=vit.encoder.layer.1.output.dense.bias]      Loading weights:  18%|█▊        | 37/200 [00:01<00:09, 16.72it/s, Materializing param=vit.encoder.layer.1.output.dense.bias]Loading weights:  19%|█▉        | 38/200 [00:01<00:09, 16.72it/s, Materializing param=vit.encoder.layer.1.output.dense.weight]Loading weights:  19%|█▉        | 38/200 [00:01<00:09, 16.72it/s, Materializing param=vit.encoder.layer.1.output.dense.weight]Loading weights:  20%|█▉        | 39/200 [00:02<00:09, 16.72it/s, Materializing param=vit.encoder.layer.2.attention.attention.key.bias]Loading weights:  20%|█▉        | 39/200 [00:02<00:09, 16.72it/s, Materializing param=vit.encoder.layer.2.attention.attention.key.bias]Loading weights:  20%|██        | 40/200 [00:02<00:09, 16.72it/s, Materializing param=vit.encoder.layer.2.attention.attention.key.weight]Loading weights:  20%|██        | 40/200 [00:02<00:09, 16.72it/s, Materializing param=vit.encoder.layer.2.attention.attention.key.weight]Loading weights:  20%|██        | 41/200 [00:02<00:09, 16.72it/s, Materializing param=vit.encoder.layer.2.attention.attention.query.bias]Loading weights:  20%|██        | 41/200 [00:02<00:09, 16.72it/s, Materializing param=vit.encoder.layer.2.attention.attention.query.bias]Loading weights:  21%|██        | 42/200 [00:02<00:05, 27.55it/s, Materializing param=vit.encoder.layer.2.attention.attention.query.bias]Loading weights:  21%|██        | 42/200 [00:02<00:05, 27.55it/s, Materializing param=vit.encoder.layer.2.attention.attention.query.weight]Loading weights:  21%|██        | 42/200 [00:02<00:05, 27.55it/s, Materializing param=vit.encoder.layer.2.attention.attention.query.weight]Loading weights:  22%|██▏       | 43/200 [00:02<00:05, 27.55it/s, Materializing param=vit.encoder.layer.2.attention.attention.value.bias]  Loading weights:  22%|██▏       | 43/200 [00:02<00:05, 27.55it/s, Materializing param=vit.encoder.layer.2.attention.attention.value.bias]Loading weights:  22%|██▏       | 44/200 [00:02<00:05, 27.55it/s, Materializing param=vit.encoder.layer.2.attention.attention.value.weight]Loading weights:  22%|██▏       | 44/200 [00:02<00:05, 27.55it/s, Materializing param=vit.encoder.layer.2.attention.attention.value.weight]Loading weights:  22%|██▎       | 45/200 [00:02<00:05, 27.55it/s, Materializing param=vit.encoder.layer.2.attention.output.dense.bias]     Loading weights:  22%|██▎       | 45/200 [00:02<00:05, 27.55it/s, Materializing param=vit.encoder.layer.2.attention.output.dense.bias]Loading weights:  23%|██▎       | 46/200 [00:02<00:05, 29.28it/s, Materializing param=vit.encoder.layer.2.attention.output.dense.bias]Loading weights:  23%|██▎       | 46/200 [00:02<00:05, 29.28it/s, Materializing param=vit.encoder.layer.2.attention.output.dense.weight]Loading weights:  23%|██▎       | 46/200 [00:02<00:05, 29.28it/s, Materializing param=vit.encoder.layer.2.attention.output.dense.weight]Loading weights:  24%|██▎       | 47/200 [00:02<00:05, 29.28it/s, Materializing param=vit.encoder.layer.2.intermediate.dense.bias]      Loading weights:  24%|██▎       | 47/200 [00:02<00:05, 29.28it/s, Materializing param=vit.encoder.layer.2.intermediate.dense.bias]Loading weights:  24%|██▍       | 48/200 [00:02<00:05, 29.28it/s, Materializing param=vit.encoder.layer.2.intermediate.dense.weight]Loading weights:  24%|██▍       | 48/200 [00:02<00:05, 29.28it/s, Materializing param=vit.encoder.layer.2.intermediate.dense.weight]Loading weights:  24%|██▍       | 49/200 [00:02<00:05, 29.28it/s, Materializing param=vit.encoder.layer.2.layernorm_after.bias]     Loading weights:  24%|██▍       | 49/200 [00:02<00:05, 29.28it/s, Materializing param=vit.encoder.layer.2.layernorm_after.bias]Loading weights:  25%|██▌       | 50/200 [00:02<00:05, 29.28it/s, Materializing param=vit.encoder.layer.2.layernorm_after.weight]Loading weights:  25%|██▌       | 50/200 [00:02<00:05, 29.28it/s, Materializing param=vit.encoder.layer.2.layernorm_after.weight]Loading weights:  26%|██▌       | 51/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.2.layernorm_after.weight]Loading weights:  26%|██▌       | 51/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.2.layernorm_before.bias] Loading weights:  26%|██▌       | 51/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.2.layernorm_before.bias]Loading weights:  26%|██▌       | 52/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.2.layernorm_before.weight]Loading weights:  26%|██▌       | 52/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.2.layernorm_before.weight]Loading weights:  26%|██▋       | 53/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.2.output.dense.bias]      Loading weights:  26%|██▋       | 53/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.2.output.dense.bias]Loading weights:  27%|██▋       | 54/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.2.output.dense.weight]Loading weights:  27%|██▋       | 54/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.2.output.dense.weight]Loading weights:  28%|██▊       | 55/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.3.attention.attention.key.bias]Loading weights:  28%|██▊       | 55/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.3.attention.attention.key.bias]Loading weights:  28%|██▊       | 56/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.3.attention.attention.key.weight]Loading weights:  28%|██▊       | 56/200 [00:02<00:04, 30.49it/s, Materializing param=vit.encoder.layer.3.attention.attention.key.weight]Loading weights:  28%|██▊       | 57/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.attention.key.weight]Loading weights:  28%|██▊       | 57/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.attention.query.bias]Loading weights:  28%|██▊       | 57/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.attention.query.bias]Loading weights:  29%|██▉       | 58/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.attention.query.weight]Loading weights:  29%|██▉       | 58/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.attention.query.weight]Loading weights:  30%|██▉       | 59/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.attention.value.bias]  Loading weights:  30%|██▉       | 59/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.attention.value.bias]Loading weights:  30%|███       | 60/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.attention.value.weight]Loading weights:  30%|███       | 60/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.attention.value.weight]Loading weights:  30%|███       | 61/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.output.dense.bias]     Loading weights:  30%|███       | 61/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.output.dense.bias]Loading weights:  31%|███       | 62/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.output.dense.weight]Loading weights:  31%|███       | 62/200 [00:02<00:04, 32.02it/s, Materializing param=vit.encoder.layer.3.attention.output.dense.weight]Loading weights:  32%|███▏      | 63/200 [00:02<00:03, 35.30it/s, Materializing param=vit.encoder.layer.3.attention.output.dense.weight]Loading weights:  32%|███▏      | 63/200 [00:02<00:03, 35.30it/s, Materializing param=vit.encoder.layer.3.intermediate.dense.bias]      Loading weights:  32%|███▏      | 63/200 [00:02<00:03, 35.30it/s, Materializing param=vit.encoder.layer.3.intermediate.dense.bias]Loading weights:  32%|███▏      | 64/200 [00:02<00:03, 35.30it/s, Materializing param=vit.encoder.layer.3.intermediate.dense.weight]Loading weights:  32%|███▏      | 64/200 [00:02<00:03, 35.30it/s, Materializing param=vit.encoder.layer.3.intermediate.dense.weight]Loading weights:  32%|███▎      | 65/200 [00:02<00:03, 35.30it/s, Materializing param=vit.encoder.layer.3.layernorm_after.bias]     Loading weights:  32%|███▎      | 65/200 [00:02<00:03, 35.30it/s, Materializing param=vit.encoder.layer.3.layernorm_after.bias]Loading weights:  33%|███▎      | 66/200 [00:02<00:03, 35.30it/s, Materializing param=vit.encoder.layer.3.layernorm_after.weight]Loading weights:  33%|███▎      | 66/200 [00:02<00:03, 35.30it/s, Materializing param=vit.encoder.layer.3.layernorm_after.weight]Loading weights:  34%|███▎      | 67/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.3.layernorm_after.weight]Loading weights:  34%|███▎      | 67/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.3.layernorm_before.bias] Loading weights:  34%|███▎      | 67/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.3.layernorm_before.bias]Loading weights:  34%|███▍      | 68/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.3.layernorm_before.weight]Loading weights:  34%|███▍      | 68/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.3.layernorm_before.weight]Loading weights:  34%|███▍      | 69/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.3.output.dense.bias]      Loading weights:  34%|███▍      | 69/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.3.output.dense.bias]Loading weights:  35%|███▌      | 70/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.3.output.dense.weight]Loading weights:  35%|███▌      | 70/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.3.output.dense.weight]Loading weights:  36%|███▌      | 71/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.attention.key.bias]Loading weights:  36%|███▌      | 71/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.attention.key.bias]Loading weights:  36%|███▌      | 72/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.attention.key.weight]Loading weights:  36%|███▌      | 72/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.attention.key.weight]Loading weights:  36%|███▋      | 73/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.attention.query.bias]Loading weights:  36%|███▋      | 73/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.attention.query.bias]Loading weights:  37%|███▋      | 74/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.attention.query.weight]Loading weights:  37%|███▋      | 74/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.attention.query.weight]Loading weights:  38%|███▊      | 75/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.attention.value.bias]  Loading weights:  38%|███▊      | 75/200 [00:02<00:04, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.attention.value.bias]Loading weights:  38%|███▊      | 76/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.attention.value.weight]Loading weights:  38%|███▊      | 76/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.attention.value.weight]Loading weights:  38%|███▊      | 77/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.output.dense.bias]     Loading weights:  38%|███▊      | 77/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.output.dense.bias]Loading weights:  39%|███▉      | 78/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.output.dense.weight]Loading weights:  39%|███▉      | 78/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.attention.output.dense.weight]Loading weights:  40%|███▉      | 79/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.intermediate.dense.bias]      Loading weights:  40%|███▉      | 79/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.intermediate.dense.bias]Loading weights:  40%|████      | 80/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.intermediate.dense.weight]Loading weights:  40%|████      | 80/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.intermediate.dense.weight]Loading weights:  40%|████      | 81/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.layernorm_after.bias]     Loading weights:  40%|████      | 81/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.layernorm_after.bias]Loading weights:  41%|████      | 82/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.layernorm_after.weight]Loading weights:  41%|████      | 82/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.layernorm_after.weight]Loading weights:  42%|████▏     | 83/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.layernorm_before.bias] Loading weights:  42%|████▏     | 83/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.layernorm_before.bias]Loading weights:  42%|████▏     | 84/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.layernorm_before.weight]Loading weights:  42%|████▏     | 84/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.layernorm_before.weight]Loading weights:  42%|████▎     | 85/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.output.dense.bias]      Loading weights:  42%|████▎     | 85/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.output.dense.bias]Loading weights:  43%|████▎     | 86/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.output.dense.weight]Loading weights:  43%|████▎     | 86/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.4.output.dense.weight]Loading weights:  44%|████▎     | 87/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.attention.key.bias]Loading weights:  44%|████▎     | 87/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.attention.key.bias]Loading weights:  44%|████▍     | 88/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.attention.key.weight]Loading weights:  44%|████▍     | 88/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.attention.key.weight]Loading weights:  44%|████▍     | 89/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.attention.query.bias]Loading weights:  44%|████▍     | 89/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.attention.query.bias]Loading weights:  45%|████▌     | 90/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.attention.query.weight]Loading weights:  45%|████▌     | 90/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.attention.query.weight]Loading weights:  46%|████▌     | 91/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.attention.value.bias]  Loading weights:  46%|████▌     | 91/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.attention.value.bias]Loading weights:  46%|████▌     | 92/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.attention.value.weight]Loading weights:  46%|████▌     | 92/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.attention.value.weight]Loading weights:  46%|████▋     | 93/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.output.dense.bias]     Loading weights:  46%|████▋     | 93/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.output.dense.bias]Loading weights:  47%|████▋     | 94/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.output.dense.weight]Loading weights:  47%|████▋     | 94/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.attention.output.dense.weight]Loading weights:  48%|████▊     | 95/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.intermediate.dense.bias]      Loading weights:  48%|████▊     | 95/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.intermediate.dense.bias]Loading weights:  48%|████▊     | 96/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.intermediate.dense.weight]Loading weights:  48%|████▊     | 96/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.intermediate.dense.weight]Loading weights:  48%|████▊     | 97/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.layernorm_after.bias]     Loading weights:  48%|████▊     | 97/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.layernorm_after.bias]Loading weights:  49%|████▉     | 98/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.layernorm_after.weight]Loading weights:  49%|████▉     | 98/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.layernorm_after.weight]Loading weights:  50%|████▉     | 99/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.layernorm_before.bias] Loading weights:  50%|████▉     | 99/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.layernorm_before.bias]Loading weights:  50%|█████     | 100/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.layernorm_before.weight]Loading weights:  50%|█████     | 100/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.layernorm_before.weight]Loading weights:  50%|█████     | 101/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.output.dense.bias]      Loading weights:  50%|█████     | 101/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.output.dense.bias]Loading weights:  51%|█████     | 102/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.output.dense.weight]Loading weights:  51%|█████     | 102/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.5.output.dense.weight]Loading weights:  52%|█████▏    | 103/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.attention.key.bias]Loading weights:  52%|█████▏    | 103/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.attention.key.bias]Loading weights:  52%|█████▏    | 104/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.attention.key.weight]Loading weights:  52%|█████▏    | 104/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.attention.key.weight]Loading weights:  52%|█████▎    | 105/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.attention.query.bias]Loading weights:  52%|█████▎    | 105/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.attention.query.bias]Loading weights:  53%|█████▎    | 106/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.attention.query.weight]Loading weights:  53%|█████▎    | 106/200 [00:02<00:03, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.attention.query.weight]Loading weights:  54%|█████▎    | 107/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.attention.value.bias]  Loading weights:  54%|█████▎    | 107/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.attention.value.bias]Loading weights:  54%|█████▍    | 108/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.attention.value.weight]Loading weights:  54%|█████▍    | 108/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.attention.value.weight]Loading weights:  55%|█████▍    | 109/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.output.dense.bias]     Loading weights:  55%|█████▍    | 109/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.output.dense.bias]Loading weights:  55%|█████▌    | 110/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.output.dense.weight]Loading weights:  55%|█████▌    | 110/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.attention.output.dense.weight]Loading weights:  56%|█████▌    | 111/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.intermediate.dense.bias]      Loading weights:  56%|█████▌    | 111/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.intermediate.dense.bias]Loading weights:  56%|█████▌    | 112/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.intermediate.dense.weight]Loading weights:  56%|█████▌    | 112/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.intermediate.dense.weight]Loading weights:  56%|█████▋    | 113/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.layernorm_after.bias]     Loading weights:  56%|█████▋    | 113/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.layernorm_after.bias]Loading weights:  57%|█████▋    | 114/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.layernorm_after.weight]Loading weights:  57%|█████▋    | 114/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.layernorm_after.weight]Loading weights:  57%|█████▊    | 115/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.layernorm_before.bias] Loading weights:  57%|█████▊    | 115/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.layernorm_before.bias]Loading weights:  58%|█████▊    | 116/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.layernorm_before.weight]Loading weights:  58%|█████▊    | 116/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.layernorm_before.weight]Loading weights:  58%|█████▊    | 117/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.output.dense.bias]      Loading weights:  58%|█████▊    | 117/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.output.dense.bias]Loading weights:  59%|█████▉    | 118/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.output.dense.weight]Loading weights:  59%|█████▉    | 118/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.6.output.dense.weight]Loading weights:  60%|█████▉    | 119/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.attention.key.bias]Loading weights:  60%|█████▉    | 119/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.attention.key.bias]Loading weights:  60%|██████    | 120/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.attention.key.weight]Loading weights:  60%|██████    | 120/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.attention.key.weight]Loading weights:  60%|██████    | 121/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.attention.query.bias]Loading weights:  60%|██████    | 121/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.attention.query.bias]Loading weights:  61%|██████    | 122/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.attention.query.weight]Loading weights:  61%|██████    | 122/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.attention.query.weight]Loading weights:  62%|██████▏   | 123/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.attention.value.bias]  Loading weights:  62%|██████▏   | 123/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.attention.value.bias]Loading weights:  62%|██████▏   | 124/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.attention.value.weight]Loading weights:  62%|██████▏   | 124/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.attention.value.weight]Loading weights:  62%|██████▎   | 125/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.output.dense.bias]     Loading weights:  62%|██████▎   | 125/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.output.dense.bias]Loading weights:  63%|██████▎   | 126/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.output.dense.weight]Loading weights:  63%|██████▎   | 126/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.attention.output.dense.weight]Loading weights:  64%|██████▎   | 127/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.intermediate.dense.bias]      Loading weights:  64%|██████▎   | 127/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.intermediate.dense.bias]Loading weights:  64%|██████▍   | 128/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.intermediate.dense.weight]Loading weights:  64%|██████▍   | 128/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.intermediate.dense.weight]Loading weights:  64%|██████▍   | 129/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.layernorm_after.bias]     Loading weights:  64%|██████▍   | 129/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.layernorm_after.bias]Loading weights:  65%|██████▌   | 130/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.layernorm_after.weight]Loading weights:  65%|██████▌   | 130/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.layernorm_after.weight]Loading weights:  66%|██████▌   | 131/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.layernorm_before.bias] Loading weights:  66%|██████▌   | 131/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.layernorm_before.bias]Loading weights:  66%|██████▌   | 132/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.layernorm_before.weight]Loading weights:  66%|██████▌   | 132/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.layernorm_before.weight]Loading weights:  66%|██████▋   | 133/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.output.dense.bias]      Loading weights:  66%|██████▋   | 133/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.output.dense.bias]Loading weights:  67%|██████▋   | 134/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.output.dense.weight]Loading weights:  67%|██████▋   | 134/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.7.output.dense.weight]Loading weights:  68%|██████▊   | 135/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.attention.key.bias]Loading weights:  68%|██████▊   | 135/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.attention.key.bias]Loading weights:  68%|██████▊   | 136/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.attention.key.weight]Loading weights:  68%|██████▊   | 136/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.attention.key.weight]Loading weights:  68%|██████▊   | 137/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.attention.query.bias]Loading weights:  68%|██████▊   | 137/200 [00:02<00:02, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.attention.query.bias]Loading weights:  69%|██████▉   | 138/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.attention.query.weight]Loading weights:  69%|██████▉   | 138/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.attention.query.weight]Loading weights:  70%|██████▉   | 139/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.attention.value.bias]  Loading weights:  70%|██████▉   | 139/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.attention.value.bias]Loading weights:  70%|███████   | 140/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.attention.value.weight]Loading weights:  70%|███████   | 140/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.attention.value.weight]Loading weights:  70%|███████   | 141/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.output.dense.bias]     Loading weights:  70%|███████   | 141/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.output.dense.bias]Loading weights:  71%|███████   | 142/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.output.dense.weight]Loading weights:  71%|███████   | 142/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.attention.output.dense.weight]Loading weights:  72%|███████▏  | 143/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.intermediate.dense.bias]      Loading weights:  72%|███████▏  | 143/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.intermediate.dense.bias]Loading weights:  72%|███████▏  | 144/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.intermediate.dense.weight]Loading weights:  72%|███████▏  | 144/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.intermediate.dense.weight]Loading weights:  72%|███████▎  | 145/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.layernorm_after.bias]     Loading weights:  72%|███████▎  | 145/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.layernorm_after.bias]Loading weights:  73%|███████▎  | 146/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.layernorm_after.weight]Loading weights:  73%|███████▎  | 146/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.layernorm_after.weight]Loading weights:  74%|███████▎  | 147/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.layernorm_before.bias] Loading weights:  74%|███████▎  | 147/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.layernorm_before.bias]Loading weights:  74%|███████▍  | 148/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.layernorm_before.weight]Loading weights:  74%|███████▍  | 148/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.layernorm_before.weight]Loading weights:  74%|███████▍  | 149/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.output.dense.bias]      Loading weights:  74%|███████▍  | 149/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.output.dense.bias]Loading weights:  75%|███████▌  | 150/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.output.dense.weight]Loading weights:  75%|███████▌  | 150/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.8.output.dense.weight]Loading weights:  76%|███████▌  | 151/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.attention.key.bias]Loading weights:  76%|███████▌  | 151/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.attention.key.bias]Loading weights:  76%|███████▌  | 152/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.attention.key.weight]Loading weights:  76%|███████▌  | 152/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.attention.key.weight]Loading weights:  76%|███████▋  | 153/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.attention.query.bias]Loading weights:  76%|███████▋  | 153/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.attention.query.bias]Loading weights:  77%|███████▋  | 154/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.attention.query.weight]Loading weights:  77%|███████▋  | 154/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.attention.query.weight]Loading weights:  78%|███████▊  | 155/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.attention.value.bias]  Loading weights:  78%|███████▊  | 155/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.attention.value.bias]Loading weights:  78%|███████▊  | 156/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.attention.value.weight]Loading weights:  78%|███████▊  | 156/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.attention.value.weight]Loading weights:  78%|███████▊  | 157/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.output.dense.bias]     Loading weights:  78%|███████▊  | 157/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.output.dense.bias]Loading weights:  79%|███████▉  | 158/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.output.dense.weight]Loading weights:  79%|███████▉  | 158/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.attention.output.dense.weight]Loading weights:  80%|███████▉  | 159/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.intermediate.dense.bias]      Loading weights:  80%|███████▉  | 159/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.intermediate.dense.bias]Loading weights:  80%|████████  | 160/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.intermediate.dense.weight]Loading weights:  80%|████████  | 160/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.intermediate.dense.weight]Loading weights:  80%|████████  | 161/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.layernorm_after.bias]     Loading weights:  80%|████████  | 161/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.layernorm_after.bias]Loading weights:  81%|████████  | 162/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.layernorm_after.weight]Loading weights:  81%|████████  | 162/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.layernorm_after.weight]Loading weights:  82%|████████▏ | 163/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.layernorm_before.bias] Loading weights:  82%|████████▏ | 163/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.layernorm_before.bias]Loading weights:  82%|████████▏ | 164/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.layernorm_before.weight]Loading weights:  82%|████████▏ | 164/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.layernorm_before.weight]Loading weights:  82%|████████▎ | 165/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.output.dense.bias]      Loading weights:  82%|████████▎ | 165/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.output.dense.bias]Loading weights:  83%|████████▎ | 166/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.output.dense.weight]Loading weights:  83%|████████▎ | 166/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.9.output.dense.weight]Loading weights:  84%|████████▎ | 167/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.attention.key.bias]Loading weights:  84%|████████▎ | 167/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.attention.key.bias]Loading weights:  84%|████████▍ | 168/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.attention.key.weight]Loading weights:  84%|████████▍ | 168/200 [00:02<00:01, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.attention.key.weight]Loading weights:  84%|████████▍ | 169/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.attention.query.bias]Loading weights:  84%|████████▍ | 169/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.attention.query.bias]Loading weights:  85%|████████▌ | 170/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.attention.query.weight]Loading weights:  85%|████████▌ | 170/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.attention.query.weight]Loading weights:  86%|████████▌ | 171/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.attention.value.bias]  Loading weights:  86%|████████▌ | 171/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.attention.value.bias]Loading weights:  86%|████████▌ | 172/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.attention.value.weight]Loading weights:  86%|████████▌ | 172/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.attention.value.weight]Loading weights:  86%|████████▋ | 173/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.output.dense.bias]     Loading weights:  86%|████████▋ | 173/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.output.dense.bias]Loading weights:  87%|████████▋ | 174/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.output.dense.weight]Loading weights:  87%|████████▋ | 174/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.attention.output.dense.weight]Loading weights:  88%|████████▊ | 175/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.intermediate.dense.bias]      Loading weights:  88%|████████▊ | 175/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.intermediate.dense.bias]Loading weights:  88%|████████▊ | 176/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.intermediate.dense.weight]Loading weights:  88%|████████▊ | 176/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.intermediate.dense.weight]Loading weights:  88%|████████▊ | 177/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.layernorm_after.bias]     Loading weights:  88%|████████▊ | 177/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.layernorm_after.bias]Loading weights:  89%|████████▉ | 178/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.layernorm_after.weight]Loading weights:  89%|████████▉ | 178/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.layernorm_after.weight]Loading weights:  90%|████████▉ | 179/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.layernorm_before.bias] Loading weights:  90%|████████▉ | 179/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.layernorm_before.bias]Loading weights:  90%|█████████ | 180/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.layernorm_before.weight]Loading weights:  90%|█████████ | 180/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.layernorm_before.weight]Loading weights:  90%|█████████ | 181/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.output.dense.bias]      Loading weights:  90%|█████████ | 181/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.output.dense.bias]Loading weights:  91%|█████████ | 182/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.output.dense.weight]Loading weights:  91%|█████████ | 182/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.10.output.dense.weight]Loading weights:  92%|█████████▏| 183/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.attention.key.bias]Loading weights:  92%|█████████▏| 183/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.attention.key.bias]Loading weights:  92%|█████████▏| 184/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.attention.key.weight]Loading weights:  92%|█████████▏| 184/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.attention.key.weight]Loading weights:  92%|█████████▎| 185/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.attention.query.bias]Loading weights:  92%|█████████▎| 185/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.attention.query.bias]Loading weights:  93%|█████████▎| 186/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.attention.query.weight]Loading weights:  93%|█████████▎| 186/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.attention.query.weight]Loading weights:  94%|█████████▎| 187/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.attention.value.bias]  Loading weights:  94%|█████████▎| 187/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.attention.value.bias]Loading weights:  94%|█████████▍| 188/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.attention.value.weight]Loading weights:  94%|█████████▍| 188/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.attention.value.weight]Loading weights:  94%|█████████▍| 189/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.output.dense.bias]     Loading weights:  94%|█████████▍| 189/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.output.dense.bias]Loading weights:  95%|█████████▌| 190/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.output.dense.weight]Loading weights:  95%|█████████▌| 190/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.attention.output.dense.weight]Loading weights:  96%|█████████▌| 191/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.intermediate.dense.bias]      Loading weights:  96%|█████████▌| 191/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.intermediate.dense.bias]Loading weights:  96%|█████████▌| 192/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.intermediate.dense.weight]Loading weights:  96%|█████████▌| 192/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.intermediate.dense.weight]Loading weights:  96%|█████████▋| 193/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.layernorm_after.bias]     Loading weights:  96%|█████████▋| 193/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.layernorm_after.bias]Loading weights:  97%|█████████▋| 194/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.layernorm_after.weight]Loading weights:  97%|█████████▋| 194/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.layernorm_after.weight]Loading weights:  98%|█████████▊| 195/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.layernorm_before.bias] Loading weights:  98%|█████████▊| 195/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.layernorm_before.bias]Loading weights:  98%|█████████▊| 196/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.layernorm_before.weight]Loading weights:  98%|█████████▊| 196/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.layernorm_before.weight]Loading weights:  98%|█████████▊| 197/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.output.dense.bias]      Loading weights:  98%|█████████▊| 197/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.output.dense.bias]Loading weights:  99%|█████████▉| 198/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.output.dense.weight]Loading weights:  99%|█████████▉| 198/200 [00:02<00:00, 31.12it/s, Materializing param=vit.encoder.layer.11.output.dense.weight]Loading weights: 100%|█████████▉| 199/200 [00:02<00:00, 31.12it/s, Materializing param=vit.layernorm.bias]                      Loading weights: 100%|█████████▉| 199/200 [00:02<00:00, 31.12it/s, Materializing param=vit.layernorm.bias]Loading weights: 100%|██████████| 200/200 [00:02<00:00, 31.12it/s, Materializing param=vit.layernorm.weight]Loading weights: 100%|██████████| 200/200 [00:02<00:00, 31.12it/s, Materializing param=vit.layernorm.weight]Loading weights: 100%|██████████| 200/200 [00:02<00:00, 69.05it/s, Materializing param=vit.layernorm.weight]
ViTForImageClassification LOAD REPORT from: google/vit-base-patch16-224
Key               | Status   |                                                                                        
------------------+----------+----------------------------------------------------------------------------------------
classifier.bias   | MISMATCH | Reinit due to size mismatch ckpt: torch.Size([1000]) vs model:torch.Size([2])          
classifier.weight | MISMATCH | Reinit due to size mismatch ckpt: torch.Size([1000, 768]) vs model:torch.Size([2, 768])
classifier.bias   | MISC     | 'Linear' object has no attribute 'param_name'
Error when processing parameter cl       
classifier.weight | MISC     | 'Linear' object has no attribute 'param_name'
Error when processing parameter cl       

Notes:
- MISMATCH	:ckpt weights were loaded, but they did not match the original empty weight.
- MISC	:originate from the conversion scheme
/home/zhisheng/stats507/train/run_finetune.py:158: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=args.use_amp)
2025-12-02 15:59:50 - INFO - train - Epoch 1/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
2025-12-02 16:12:53 - INFO - train - Train metrics: {
  "accuracy": 0.6304705882352941,
  "auroc": 0.5685116623483975,
  "macro_f1": 0.5099733819839025,
  "loss": 0.6569749154203078
}
2025-12-02 16:14:17 - INFO - train - Val metrics: {
  "accuracy": 0.5634615384615385,
  "auroc": 0.5412059410497565,
  "macro_f1": 0.51258588794926,
  "loss": 0.6981478012525119
}
2025-12-02 16:14:21 - INFO - train - Saved new best checkpoint with AUROC=0.5412
2025-12-02 16:14:21 - INFO - train - Epoch 2/10
/home/zhisheng/stats507/train/loops.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
slurmstepd: error: *** JOB 37086023 ON gl1002 CANCELLED AT 2025-12-02T16:14:56 ***
